<!-- HTML header for doxygen 1.8.5-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<title>DNNL: Profiling DNNL performance</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script src="assets/mathjax/MathJax.js?config=TeX-AMS_CHTML,dnnl"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Montserrat" rel="stylesheet">
<link href="assets/customdoxygen.css" rel="stylesheet" type="text/css" />
<script type="text/javascript" src="assets/dnn.js"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
   <div id="projectname">Deep Neural Network Library (DNNL)
   &#160;<span id="projectnumber">1.3.0</span>
   </div>
   <div id="projectbrief">Performance library for Deep Learning</div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Profiling DNNL performance </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>DNNL uses JIT (just-in-time) code generation based on primitive parameters and instruction set supported by the system. In order to correctly attribute performance event information, profilers need to be notified about address ranges containing JIT-ed code. DNNL supports two profilers: Intel VTune Amplifier and Linux perf.</p>
<p>At build-time, support for this feature is controlled via cmake option <code>DNNL_ENABLE_JIT_PROFILING</code>:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadLeft">Option  </th><th class="markdownTableHeadLeft">Possible Values (defaults in bold)  </th><th class="markdownTableHeadLeft">Desc   </th></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">DNNL_ENABLE_JIT_PROFILING  </td><td class="markdownTableBodyLeft"><b>ON</b>, OFF  </td><td class="markdownTableBodyLeft">Enables integration with performance profilers   </td></tr>
</table>
<p>At run-time, this feature can be controlled via the following two functions:</p>
<ul>
<li><a class="el" href="group__dnnl__api__service.html#ga51ef634e4f201a12d32e573955943f48">dnnl_set_jit_profiling_flags</a></li>
<li><a class="el" href="group__dnnl__api__service.html#gafb0fb0d37d72bc58386ba97bb858f8f7">dnnl_set_jit_profiling_jitdumpdir</a></li>
</ul>
<p>or via the <code>DNNL_JIT_PROFILE</code> environment variable which accepts the same values as the <a class="el" href="group__dnnl__api__service.html#ga51ef634e4f201a12d32e573955943f48">dnnl_set_jit_profiling_flags</a> function. The following individual flags may be OR-ed:</p>
<ul>
<li><a class="el" href="group__dnnl__api__service.html#ga137013d98ef736973ebbe1ecd4a4b2c9">DNNL_JIT_PROFILE_VTUNE</a> = 1: Enable VTune integration.</li>
<li><a class="el" href="group__dnnl__api__service.html#gacb5b174589525cce34589ef4ef56462f">DNNL_JIT_PROFILE_LINUX_PERFMAP</a> = 2: Enable Linux perf integration via perfmap files.</li>
<li><a class="el" href="group__dnnl__api__service.html#ga5afb7d615d8507b8d5469553e6dde2a7">DNNL_JIT_PROFILE_LINUX_JITDUMP</a> = 4: Enable Linux perf integration via jitdump files.</li>
<li><a class="el" href="group__dnnl__api__service.html#ga66a48a940ab2916d360b0bb677a70e5f">DNNL_JIT_PROFILE_LINUX_JITDUMP_USE_TSC</a> = 8: Instruct Linux perf integration via jitdump files to use TSC.</li>
</ul>
<p>The default setting of the profiling flags is to enable integration with Intel VTune Amplifier, therefore it does not require any additional setup and works out of the box. Code integrating DNNL may override this behavior.</p>
<h2>Example: profiling with Intel VTune Amplifier</h2>
<p>Assuming that environment is set up already.</p>
<p>Collect profiling data:</p>
<div class="fragment"><div class="line">$ amplxe-cl -collect hotspots -q -no-summary -knob sampling-mode=hw -r dnnl-vtune ./benchdnn --mode=P mb1ic32ih14oc32oh14kh3ph1n&quot;resnet_50:res4a_branch2b*6&quot;</div><div class="line">amplxe: Warning: To enable hardware event-base sampling, VTune Amplifier has disabled the NMI watchdog timer. The watchdog timer will be re-enabled after collection completes.</div><div class="line">Output template: perf,%engine%,%name%,%desc%,%Gops%,%Gfreq%,%-time%,%-Gflops%,%0time%,%0Gflops%</div><div class="line">perf,cpu,resnet_50:res4a_branch2b*6,--conv mb1ic32ih14oc32oh14kh3ph1nresnet_50:res4a_branch2b*6,0.0032768,0,2.13525,1.53462,4.32546,0.757561</div><div class="line">tests:1 passed:0 skipped:0 mistrusted:0 unimplemented:0 failed:0 listed:0</div><div class="line">total perf: min(ms):2.13525 avg(ms):4.32546</div></div><!-- fragment --><dl class="section note"><dt>Note</dt><dd>You don't need to set <code>DNNL_JIT_PROFILE</code> environment variable.</dd></dl>
<p>Display top 10 hotspots using command-line interface:</p>
<div class="fragment"><div class="line">$ amplxe-cl -report hotspots -q -r dnnl-vtune -format csv -csv-delimiter &#39;;&#39; -group-by process,module,function -column &#39;CPU Time:Self&#39; | head -n 10 | column -t -s&#39;;&#39;</div><div class="line">Column filter is ON.</div><div class="line">Process   Module            Function                                                                                                                           CPU Time</div><div class="line">benchdnn  libgomp.so.1.0.0  do_spin                                                                                                                            54.796608</div><div class="line">benchdnn  libgomp.so.1.0.0  do_spin                                                                                                                            52.075321</div><div class="line">benchdnn  libgomp.so.1.0.0  cpu_relax                                                                                                                          3.979194</div><div class="line">benchdnn  libgomp.so.1.0.0  cpu_relax                                                                                                                          3.838870</div><div class="line">benchdnn  [Dynamic code]    jit_avx2_conv_fwd_kernel_f32                                                                                                       2.355442</div><div class="line">benchdnn  vmlinux           __lock_acquire                                                                                                                     0.801853</div><div class="line">benchdnn  vmlinux           do_raw_spin_lock                                                                                                                   0.290672</div><div class="line">benchdnn  libdnnl.so.1.1    dnnl::impl::cpu::jit_avx2_convolution_fwd_t::execute_forward(dnnl::impl::exec_ctx_t const&amp;) const::{lambda(intint)#1}::operator()  0.260602</div><div class="line">benchdnn  vmlinux           plist_check_prev_next                                                                                                              0.115266</div></div><!-- fragment --><p>The JIT-ed function <code>jit_avx2_conv_fwd_kernel_f32</code> is shown as belonging to the <code>[Dynamic code]</code> module.</p>
<p>See more examples in the <a href="https://software.intel.com/en-us/vtune-amplifier-help-tutorials-and-samples">Intel VTune Amplifier User Guide</a></p>
<h2>Example: profiling with Linux perf</h2>
<p>The following command instructs DNNL to enable both jitdump and perfmap profiling modes and write jitdump files into <code>.debug</code> directory in the current directory by setting environment variable <code>JITDUMPDIR</code> to point to the current directory.</p>
<div class="fragment"><div class="line">$ JITDUMPDIR=. DNNL_JIT_PROFILE=6 perf record -k1 ./tests/benchdnn/benchdnn --mode=P mb1ic32ih14oc32oh14kh3ph1n&quot;resnet_50:res4a_branch2b*6&quot;</div><div class="line">Output template: perf,%engine%,%name%,%desc%,%Gops%,%Gfreq%,%-time%,%-Gflops%,%0time%,%0Gflops%</div><div class="line">perf,cpu,resnet_50:res4a_branch2b*6,--conv mb1ic32ih14oc32oh14kh3ph1nresnet_50:res4a_branch2b*6,0.0032768,0,0.0131836,248.551,0.0262988,124.599</div><div class="line">tests:1 passed:0 skipped:0 mistrusted:0 unimplemented:0 failed:0 listed:0</div><div class="line">total perf: min(ms):0.0131836 avg(ms):0.0262988</div><div class="line">[ perf record: Woken up 1 times to write data ]</div><div class="line">[ perf record: Captured and wrote 0.884 MB perf.data (23102 samples) ]</div></div><!-- fragment --><p>The following command injects the information from the jitdump files into the performance data: </p><div class="fragment"><div class="line">$ perf inject -j -i perf.data -o perf.data.j</div></div><!-- fragment --><p>The following command displays the top hotspots: </p><div class="fragment"><div class="line">$ perf report -i perf.data.j --stdio | head -n20</div><div class="line"># To display the perf.data header info, please use --header/--header-only options.</div><div class="line">#</div><div class="line">#</div><div class="line"># Total Lost Samples: 0</div><div class="line">#</div><div class="line"># Samples: 23K of event &#39;cpu-clock:uhH&#39;</div><div class="line"># Event count (approx.): 5775500000</div><div class="line">#</div><div class="line"># Overhead  Command   Shared Object        Symbol</div><div class="line">#</div><div class="line">    39.33%  benchdnn  libgomp.so.1.0.0     [.] 0x000000000001d8ba</div><div class="line">    29.41%  benchdnn  jitted-31475-0.so    [.] jit_avx2_conv_fwd_kernel_f32</div><div class="line">    20.49%  benchdnn  libgomp.so.1.0.0     [.] 0x000000000001d712</div><div class="line">     3.47%  benchdnn  libdnnl.so.1.1       [.] dnnl::impl::cpu::jit_avx2_convolution_fwd_t::execute_forward(dnnl::impl::exec_ctx_t const&amp;) const::{lambda(int, int)#1}::operator()</div><div class="line">     1.52%  benchdnn  libgomp.so.1.0.0     [.] 0x000000000001d8be</div><div class="line">     0.93%  benchdnn  libgomp.so.1.0.0     [.] 0x000000000001d716</div><div class="line">     0.75%  benchdnn  libgomp.so.1.0.0     [.] 0x000000000001d8c5</div><div class="line">     0.55%  benchdnn  libgomp.so.1.0.0     [.] 0x000000000001d8c3</div><div class="line">     0.46%  benchdnn  libgomp.so.1.0.0     [.] 0x000000000001d71d</div></div><!-- fragment --><dl class="section note"><dt>Note</dt><dd>Not every kernel / distribution support displaying detailed profiling information. Symbol resolution (usually) works as long as the perfmap mode is enabled, but annotating a JIT-ed functions disassembly, which requires jitdump, seems to often fail on kernels before 5.x.</dd></dl>
<p>See more on the <a href="http://www.brendangregg.com/perf.html">Brendan Gregg's excellent perf examples page</a> </p>
</div></div><!-- contents -->
<div class="footer">
    <div class="footer-wrapper">
        <ul id="footer-links">
            <li><a href="legal_information.html">Legal information</a></li>
        </ul>
    </div>
</div>