<!-- HTML header for doxygen 1.8.5-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<title>Intel(R) MKL-DNN: Softmax</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script src="assets/mathjax/MathJax.js?config=TeX-AMS_CHTML"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Montserrat" rel="stylesheet">
<link href="assets/customdoxygen.css" rel="stylesheet" type="text/css" />
<script type="text/javascript" src="assets/dnn.js"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
   <div id="projectname">Intel(R) Math Kernel Library for Deep Neural Networks (Intel(R) MKL-DNN)
   &#160;<span id="projectnumber">1.0.4</span>
   </div>
   <div id="projectbrief">Performance library for Deep Learning</div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Softmax </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><blockquote class="doxtable">
<p></p>
<p>API reference: <a class="el" href="group__c__api__softmax.html">C</a>, <a class="el" href="group__cpp__api__softmax.html">C++</a></p>
<p></p>
</blockquote>
<p>The softmax primitive performs softmax along a particular axis on data with arbitrary dimensions. All other axes are treated as independent (batch).</p>
<p>In general form, the operation is defined by the following formulas:</p>
<h3>Forward</h3>
<p class="formulaDsp">
\[ dst(\overline{ou}, c, \overline{in}) = \frac {e^{src(\overline{ou}, c, \overline{in}) - \nu(\overline{ou}, \overline{in})}} { \sum\limits_{ic} e^{src(\overline{ou}, ic, \overline{in}) - \nu(\overline{ou}, \overline{in})} }, \]
</p>
<p>where</p>
<ul>
<li>\(c\) dimension is called a softmax axis,</li>
<li>\(\overline{ou}\) is the outermost indices (to the left from softmax axis),</li>
<li>\(\overline{in}\) is the innermost indices (to the right from softmax axis), and</li>
<li><p class="startli">\(\nu\) is used to produce more accurate results and defined as:</p>
<p class="formulaDsp">
\[ \nu(\overline{ou}, \overline{in}) = \max\limits_{ic} src(\overline{ou}, ic, \overline{in}) \]
</p>
</li>
</ul>
<h4>Difference Between <a href="#mkldnn_forward_training">Forward Training</a> and <a href="#mkldnn_forward_inference">Forward Inference</a></h4>
<p>There is no difference between the <a class="el" href="group__c__api__types__generic.html#gga5b98c8059c2aff8861157bf070c3f520a0bb8fb5a8f3ae67cf8d9c8d13667507f" title="Forward data propagation (training mode). ">mkldnn_forward_training</a> and <a class="el" href="group__c__api__types__generic.html#gga5b98c8059c2aff8861157bf070c3f520a58a923fb6c4e1214e1505b5fa0b1e3fa" title="Forward data propagation (inference mode). ">mkldnn_forward_inference</a> propagation kinds.</p>
<h3>Backward</h3>
<p>The backward propagation computes \(diff\_src(ou, c, in)\), based on \(diff\_dst(ou, c, in)\) and \(dst(ou, c, in)\).</p>
<h2>Implementation Details</h2>
<h3>General Notes</h3>
<p>N/A</p>
<h3>Post-ops and Attributes</h3>
<p>The softmax primitive doesn't support any post-ops or attributes.</p>
<h3>Data Type Support</h3>
<p>The softmax primitive supports the following combinations of data types:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadLeft">Propagation  </th><th class="markdownTableHeadLeft">Sou   </th></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">forward / backward  </td><td class="markdownTableBodyLeft">f32   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyLeft">forward  </td><td class="markdownTableBodyLeft">f16   </td></tr>
</table>
<h3>Data Representation</h3>
<h4>Source, Destination, and Their Gradients</h4>
<p>The softmax primitive works with arbitrary data tensors. There is no special meaning associated with any logical dimensions. However, the softmax axis is typically referred to as channels (hence in formulas we use \(c\)).</p>
<h2>Implementation Limitations</h2>
<ol type="1">
<li>No primitive specific limitations. Refer to <a class="el" href="dev_guide_data_types.html">Data Types</a> for limitations related to data types support.</li>
</ol>
<h2>Performance Tips</h2>
<ul>
<li>Currently the softmax primitive is optimized for the cases where the dimension of the softmax axis is physically dense. For instance:<ul>
<li>Optimized: 2D case, tensor \(A \times B\), softmax axis 1 (B), format tag <a class="el" href="group__c__api__types__generic.html#ggacc2844e341ab1c4f5b7ae1c6068f2a2ba50ffa304d45d50709fdc192f6b286163" title="plain 2D tensor ">mkldnn_ab</a></li>
<li>Optimized: 4D case, tensor \(A \times B \times C \times D\), softmax axis 3 (D), format tag <a class="el" href="group__c__api__types__generic.html#ggacc2844e341ab1c4f5b7ae1c6068f2a2ba63203c48f8a6ff36dbf21e8c81bca060" title="plain 4D tensor ">mkldnn_abcd</a></li>
<li>Optimized: 4D case, tensor \(A \times B \times C \times D\), softmax axis 1 (B), format tag <a class="el" href="group__c__api__types__generic.html#ggacc2844e341ab1c4f5b7ae1c6068f2a2ba63203c48f8a6ff36dbf21e8c81bca060" title="plain 4D tensor ">mkldnn_abcd</a>, and \(C = D = 1\)</li>
<li>Non-optimized: 2D case, tensor \(A \times B\), softmax axis 0 (A), format tag <a class="el" href="group__c__api__types__generic.html#ggacc2844e341ab1c4f5b7ae1c6068f2a2ba50ffa304d45d50709fdc192f6b286163" title="plain 2D tensor ">mkldnn_ab</a>, and \(B \ne 1\)</li>
<li>Non-optimized: 2D case, tensor \(A \times B\), softmax axis 1 (B), format tag <a class="el" href="group__c__api__types__generic.html#ggacc2844e341ab1c4f5b7ae1c6068f2a2baa1b1a627050d3f5d5477b4bf662c1f95" title="permuted 2D tensor ">mkldnn_ba</a>, and \(A \ne 1\)</li>
<li>Non-optimized: 4D case, tensor \(A \times B\), softmax axis 2 (C), format tag <a class="el" href="group__c__api__types__generic.html#ggacc2844e341ab1c4f5b7ae1c6068f2a2ba5bdb52f009d9c8b46aaf05119cf18592" title="permuted 4D tensor ">mkldnn_acdb</a>, and and \(D \cdot B \ne 1\) </li>
</ul>
</li>
</ul>
</div></div><!-- contents -->
<div class="footer">
    <div class="footer-wrapper">
        <ul id="footer-links">
            <li><a href="legal_information.html">Legal information</a></li>
        </ul>
    </div>
</div>