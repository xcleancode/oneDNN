<!-- HTML header for doxygen 1.8.5-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<title>Intel(R) MKL-DNN: Eltwise</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script src="assets/mathjax/MathJax.js?config=TeX-AMS_CHTML"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Montserrat" rel="stylesheet">
<link href="assets/customdoxygen.css" rel="stylesheet" type="text/css" />
<script type="text/javascript" src="assets/dnn.js"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
   <div id="projectname">Intel(R) Math Kernel Library for Deep Neural Networks (Intel(R) MKL-DNN)
   &#160;<span id="projectnumber">1.0.4</span>
   </div>
   <div id="projectbrief">Performance library for Deep Learning</div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Eltwise </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><blockquote class="doxtable">
<p></p>
<p>API reference: <a class="el" href="group__c__api__eltwise.html">C</a>, <a class="el" href="group__cpp__api__eltwise.html">C++</a></p>
<p></p>
</blockquote>
<p>The eltwise primitive applies an operation to every element of the tensor:</p>
<p class="formulaDsp">
\[ dst(\overline{x}) = Operation(src(\overline{x})), \]
</p>
<p>where \(\overline{x} = (x_n, .., x_0)\).</p>
<p>The following operations are supported:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadLeft">Operation  </th><th class="markdownTableHeadLeft">MKL-DNN algorithm kind  </th><th class="markdownTableHeadLeft">For   </th></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">abs  </td><td class="markdownTableBodyLeft"><a class="el" href="group__c__api__types__generic.html#ggaa27d43cdd1e439cc41a9580d23ce3e97acdc9ab2cd85eae9d8ad1fa11db97543e" title="Eltwise: abs. ">mkldnn_eltwise_abs</a>  </td><td class="markdownTableBodyLeft">\( f(x) = \begin{cases} x &amp; \text{if}\ x &gt; 0 \\ \alpha -x &amp; \text{if}\ x \leq 0 \end{cases} \)   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyLeft">bounded_relu  </td><td class="markdownTableBodyLeft"><a class="el" href="group__c__api__types__generic.html#ggaa27d43cdd1e439cc41a9580d23ce3e97a7e86d17d0b611f2c80d299668d883bad" title="Eltwise: bounded_relu. ">mkldnn_eltwise_bounded_relu</a>  </td><td class="markdownTableBodyLeft">\( f(x) = \begin{cases} \alpha &amp; \text{if}\ x &gt; \alpha \\ \alpha x &amp; \text{if}\ x \leq \alpha \end{cases} \)   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">elu  </td><td class="markdownTableBodyLeft"><a class="el" href="group__c__api__types__generic.html#ggaa27d43cdd1e439cc41a9580d23ce3e97a9d438b0d2d277674da5f54990e029015" title="Eltwise: parametric exponential linear unit (elu) ">mkldnn_eltwise_elu</a>  </td><td class="markdownTableBodyLeft">\( f(x) = \begin{cases} x &amp; \text{if}\ x &gt; 0 \\ \alpha (e^x - 1) &amp; \text{if}\ x \leq 0 \end{cases} \)   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyLeft">exp  </td><td class="markdownTableBodyLeft"><a class="el" href="group__c__api__types__generic.html#ggaa27d43cdd1e439cc41a9580d23ce3e97a0edb1d73453a748b0b4e5fe705e8311e" title="Eltwise: exponent. ">mkldnn_eltwise_exp</a>  </td><td class="markdownTableBodyLeft">\( f(x) = e^x \)   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">gelu  </td><td class="markdownTableBodyLeft"><a class="el" href="group__c__api__types__generic.html#ggaa27d43cdd1e439cc41a9580d23ce3e97af446cf3eadfdb070bbbeb237f2ae94fe" title="Eltwise: gelu. ">mkldnn_eltwise_gelu</a>  </td><td class="markdownTableBodyLeft">\( f(x) = 0.5 x (1 + tanh[\sqrt{\frac{2}{\pi}} (x + 0.044715 x^3)])\)   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyLeft">linear  </td><td class="markdownTableBodyLeft"><a class="el" href="group__c__api__types__generic.html#ggaa27d43cdd1e439cc41a9580d23ce3e97a32f9fc43254ed1896e45cfcb6808d807" title="Eltwise: linear. ">mkldnn_eltwise_linear</a>  </td><td class="markdownTableBodyLeft">\( f(x) = \alpha x + \beta \)   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">logistic  </td><td class="markdownTableBodyLeft"><a class="el" href="group__c__api__types__generic.html#ggaa27d43cdd1e439cc41a9580d23ce3e97a4bd7b82c022d4cf43c474e5bf476cb24" title="Eltwise: logistic. ">mkldnn_eltwise_logistic</a>  </td><td class="markdownTableBodyLeft">\( f(x) = \frac{1}{1+e^{-x}} \)   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyLeft">relu  </td><td class="markdownTableBodyLeft"><a class="el" href="group__c__api__types__generic.html#ggaa27d43cdd1e439cc41a9580d23ce3e97a66ead6848424f0b494e813745efb5548" title="Eltwise: ReLU. ">mkldnn_eltwise_relu</a>  </td><td class="markdownTableBodyLeft">\( f(x) = \begin{cases} x &amp; \text{if}\ x &gt; 0 \\ \alpha x &amp; \text{if}\ x \leq 0 \end{cases} \)   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">soft_relu  </td><td class="markdownTableBodyLeft"><a class="el" href="group__c__api__types__generic.html#ggaa27d43cdd1e439cc41a9580d23ce3e97ac99f9e82b0c4c4583856664870469016" title="Eltwise: soft_relu. ">mkldnn_eltwise_soft_relu</a>  </td><td class="markdownTableBodyLeft">\( f(x) = \log_{e}(1+e^x) \)   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyLeft">sqrt  </td><td class="markdownTableBodyLeft"><a class="el" href="group__c__api__types__generic.html#ggaa27d43cdd1e439cc41a9580d23ce3e97aca916768654a670e8bfdb0cf41b8a1a7" title="Eltwise: square root. ">mkldnn_eltwise_sqrt</a>  </td><td class="markdownTableBodyLeft">\( f(x) = \sqrt{x} \)   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">square  </td><td class="markdownTableBodyLeft"><a class="el" href="group__c__api__types__generic.html#ggaa27d43cdd1e439cc41a9580d23ce3e97af4f3e47ddb2105e7c2ddf1bbd8434d02" title="Eltwise: square. ">mkldnn_eltwise_square</a>  </td><td class="markdownTableBodyLeft">\( f(x) = x^2 \)   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyLeft">tanh  </td><td class="markdownTableBodyLeft"><a class="el" href="group__c__api__types__generic.html#ggaa27d43cdd1e439cc41a9580d23ce3e97a6b50624e847783bfc94b7cf6badfa16c" title="Eltwise: hyperbolic tangent non-linearity (tanh) ">mkldnn_eltwise_tanh</a>  </td><td class="markdownTableBodyLeft">\( f(x) = \frac{e^z - e^{-z}}{e^z + e^{-z}} \)   </td></tr>
</table>
<h4>Difference Between <a href="#mkldnn_forward_training">Forward Training</a> and <a href="#mkldnn_forward_inference">Forward Inference</a></h4>
<p>There is no difference between the <a class="el" href="group__c__api__types__generic.html#gga5b98c8059c2aff8861157bf070c3f520a0bb8fb5a8f3ae67cf8d9c8d13667507f" title="Forward data propagation (training mode). ">mkldnn_forward_training</a> and <a class="el" href="group__c__api__types__generic.html#gga5b98c8059c2aff8861157bf070c3f520a58a923fb6c4e1214e1505b5fa0b1e3fa" title="Forward data propagation (inference mode). ">mkldnn_forward_inference</a> propagation kinds.</p>
<h3>Backward</h3>
<p>The backward propagation computes \(diff\_src(\overline{x})\), based on \(diff\_dst(\overline{x})\) and \(src(\overline{x})\).</p>
<h2>Implementation Details</h2>
<h3>General Notes</h3>
<ol type="1">
<li>All eltise primitives have a common initialization function (e.g., mkldnn::eltwise_forward::desc::desc()) which takes both parameters \(\alpha\), and \(\beta\). These parameters are ignored if they are unused.</li>
<li>The memory format and data type for <code>src</code> and <code>dst</code> are assumed to be the same, and in the API are typically referred as <code>data</code> (e.g., see <code>data_desc</code> in mkldnn::eltwise_forward::desc::desc()). The same holds for <code>diff_src</code> and <code>diff_dst</code>. The corresponding memory descriptors are referred to as <code>diff_data_desc</code>.</li>
<li>Both forward and backward propagation support in-place operations, meaning that <code>src</code> can be used as input and output for forward propagation, and <code>diff_dst</code> can be used as input and output for backward propagation. In case of in-place operation, the original data will be overwritten.</li>
<li>For some operations it might be performance beneficial to compute backward propagation based on \(dst(\overline{x})\), rather than on \(src(\overline{x})\). However, for some other operations this is simply impossible. So for generality the library always requires \(src\).</li>
</ol>
<dl class="section note"><dt>Note</dt><dd>For the ReLU operation with \(\alpha = 0\), \(dst\) can be used instead of \(src\) and \(dst\) when backward propagation is computed. This enables several performance optimizations (see the tips below).</dd></dl>
<h3>Data Type Support</h3>
<p>The eltwise primitive supports the following combinations of data types:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadLeft">Propagation  </th><th class="markdownTableHeadLeft">Source / Destination  </th><th class="markdownTableHeadLeft">Int   </th></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">forward / backward  </td><td class="markdownTableBodyLeft">f32  </td><td class="markdownTableBodyLeft">f32   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyLeft">forward  </td><td class="markdownTableBodyLeft">f16  </td><td class="markdownTableBodyLeft">f16   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">forward  </td><td class="markdownTableBodyLeft">s32 / s8 / u8  </td><td class="markdownTableBodyLeft">f32   </td></tr>
</table>
<dl class="section warning"><dt>Warning</dt><dd>There might be hardware and/or implementation specific restrictions. Check <a class="el" href="dev_guide_eltwise.html#dg_eltwise_impl_limits">Implementation Limitations</a> section below.</dd></dl>
<p>Here the intermediate data type means that the values coming in are first converted to the intermediate data type, then the operation is applied, and finally the result is converted to the output data type.</p>
<h3>Data Representation</h3>
<p>The eltwise primitive works with arbitrary data tensors. There is no special meaning associated with any logical dimensions.</p>
<h3>Post-ops and Attributes</h3>
<p>The eltwise primitive doesn't support any post-ops or attributes.</p>
<p><a class="anchor" id="dg_eltwise_impl_limits"></a></p><h2>Implementation Limitations</h2>
<ol type="1">
<li>No primitive specific limitations. Refer to <a class="el" href="dev_guide_data_types.html">Data Types</a> for limitations related to data types support.</li>
</ol>
<h2>Performance Tips</h2>
<ol type="1">
<li>For backward propagation, use the same memory format for <code>src</code>, <code>diff_dst</code>, and <code>diff_src</code> (the format of the <code>diff_dst</code> and <code>diff_src</code> are always the same because of the API). Different formats are functionally supported but lead to highly suboptimal performance.</li>
<li>Use in-place operations whenever possible.</li>
<li>As mentioned above for the ReLU operation with \(\alpha = 0\), one can use the \(dst\) tensor instead of \(src\). This enables the following potential optimizations for training:<ul>
<li>ReLU can be safely done in-place.</li>
<li>Moreover, ReLU can be fused as a <a class="el" href="dev_guide_attributes.html">post-op</a> with the previous operation if that operation doesn't require its \(dst\) to compute the backward propagation (e.g., if the convolution operation satisfies these conditions). </li>
</ul>
</li>
</ol>
</div></div><!-- contents -->
<div class="footer">
    <div class="footer-wrapper">
        <ul id="footer-links">
            <li><a href="legal_information.html">Legal information</a></li>
        </ul>
    </div>
</div>