<!-- HTML header for doxygen 1.8.5-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<title>Intel(R) MKL-DNN: cpu_cnn_inference_int8.cpp</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script src="assets/mathjax/MathJax.js?config=TeX-AMS_CHTML"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Montserrat" rel="stylesheet">
<link href="assets/customdoxygen.css" rel="stylesheet" type="text/css" />
<script type="text/javascript" src="assets/dnn.js"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
   <div id="projectname">Intel(R) Math Kernel Library for Deep Neural Networks (Intel(R) MKL-DNN)
   &#160;<span id="projectnumber">1.0.4</span>
   </div>
   <div id="projectbrief">Performance library for Deep Learning</div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">cpu_cnn_inference_int8.cpp</div>  </div>
</div><!--header-->
<div class="contents">
<p>This C++ API example demonstrates how to run AlexNet's conv3 and relu3 with int8 data type. </p><blockquote class="doxtable">
<p>Annotated version: <a class="el" href="cpu_cnn_inference_int8_cpp.html">CNN int8 inference example</a> </p>
</blockquote>
<div class="fragment"><div class="line"><span class="comment">/*******************************************************************************</span></div><div class="line"><span class="comment">* Copyright 2018-2019 Intel Corporation</span></div><div class="line"><span class="comment">*</span></div><div class="line"><span class="comment">* Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></div><div class="line"><span class="comment">* you may not use this file except in compliance with the License.</span></div><div class="line"><span class="comment">* You may obtain a copy of the License at</span></div><div class="line"><span class="comment">*</span></div><div class="line"><span class="comment">*     http://www.apache.org/licenses/LICENSE-2.0</span></div><div class="line"><span class="comment">*</span></div><div class="line"><span class="comment">* Unless required by applicable law or agreed to in writing, software</span></div><div class="line"><span class="comment">* distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></div><div class="line"><span class="comment">* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></div><div class="line"><span class="comment">* See the License for the specific language governing permissions and</span></div><div class="line"><span class="comment">* limitations under the License.</span></div><div class="line"><span class="comment">*******************************************************************************/</span></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="mkldnn_8hpp.html">mkldnn.hpp</a>&quot;</span></div><div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div><div class="line"><span class="preprocessor">#include &lt;numeric&gt;</span></div><div class="line"><span class="preprocessor">#include &lt;string&gt;</span></div><div class="line"></div><div class="line"><span class="keyword">using namespace </span><a class="code" href="namespacemkldnn.html">mkldnn</a>;</div><div class="line"></div><div class="line">memory::dim product(<span class="keyword">const</span> memory::dims &amp;dims) {</div><div class="line">    <span class="keywordflow">return</span> std::accumulate(dims.begin(), dims.end(), (memory::dim)1,</div><div class="line">            std::multiplies&lt;memory::dim&gt;());</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keywordtype">void</span> simple_net_int8() {</div><div class="line">    <span class="keyword">using</span> tag = <a name="a0"></a><a class="code" href="structmkldnn_1_1memory.html#a123930e31c5460c2c5f052a59c2a4ced">memory::format_tag</a>;</div><div class="line">    <span class="keyword">using</span> dt = <a name="a1"></a><a class="code" href="structmkldnn_1_1memory.html#aa8a0d49cc7faaceef9d8f55d66bff57b">memory::data_type</a>;</div><div class="line"></div><div class="line">    <span class="keyword">auto</span> cpu_engine = <a name="a2"></a><a class="code" href="group__cpp__api__enums.html#gga6d88ff11a07bae09a5c348d314c5d1d9aad1943a9fd6d3d7ee1e6af41a5b0d3e7">engine</a>(<a name="a3"></a><a class="code" href="structmkldnn_1_1engine.html#a81bcf1ea92d7f98852a2c3e187825de6ad9747e2da342bdb995f6389533ad1a3d">engine::kind::cpu</a>, 0);</div><div class="line">    <a name="_a4"></a><a class="code" href="structmkldnn_1_1stream.html">stream</a> s(cpu_engine);</div><div class="line"></div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">int</span> batch = 8;</div><div class="line"></div><div class="line"><span class="comment">//[Configure tensor shapes]</span></div><div class="line">    <span class="comment">// AlexNet: conv3</span></div><div class="line">    <span class="comment">// {batch, 256, 13, 13} (x)  {384, 256, 3, 3}; -&gt; {batch, 384, 13, 13}</span></div><div class="line">    <span class="comment">// strides: {1, 1}</span></div><div class="line">    memory::dims conv_src_tz = { batch, 256, 13, 13 };</div><div class="line">    memory::dims conv_weights_tz = { 384, 256, 3, 3 };</div><div class="line">    memory::dims conv_bias_tz = { 384 };</div><div class="line">    memory::dims conv_dst_tz = { batch, 384, 13, 13 };</div><div class="line">    memory::dims conv_strides = { 1, 1 };</div><div class="line">    memory::dims conv_padding = { 1, 1 };</div><div class="line"><span class="comment">//[Configure tensor shapes]</span></div><div class="line"></div><div class="line"><span class="comment">//[Choose scaling factors]</span></div><div class="line">    <span class="comment">// Choose scaling factors for input, weight, output and bias quantization</span></div><div class="line">    <span class="keyword">const</span> std::vector&lt;float&gt; src_scales = { 1.8f };</div><div class="line">    <span class="keyword">const</span> std::vector&lt;float&gt; weight_scales = { 2.0f };</div><div class="line">    <span class="keyword">const</span> std::vector&lt;float&gt; bias_scales = { 1.0f };</div><div class="line">    <span class="keyword">const</span> std::vector&lt;float&gt; dst_scales = { 0.55f };</div><div class="line"></div><div class="line">    <span class="comment">// Choose channel-wise scaling factors for convolution</span></div><div class="line">    std::vector&lt;float&gt; conv_scales(384);</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">int</span> scales_half = 384 / 2;</div><div class="line">    std::fill(conv_scales.begin(), conv_scales.begin() + scales_half, 0.3f);</div><div class="line">    std::fill(conv_scales.begin() + scales_half + 1, conv_scales.end(), 0.8f);</div><div class="line"><span class="comment">//[Choose scaling factors]</span></div><div class="line"></div><div class="line"><span class="comment">//[Set scaling mask]</span></div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">int</span> src_mask = 0;</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">int</span> weight_mask = 0;</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">int</span> bias_mask = 0;</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">int</span> dst_mask = 0;</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">int</span> conv_mask = 2; <span class="comment">// 1 &lt;&lt; output_channel_dim</span></div><div class="line"><span class="comment">//[Set scaling mask]</span></div><div class="line"></div><div class="line">    <span class="comment">// Allocate input and output buffers for user data</span></div><div class="line">    std::vector&lt;float&gt; user_src(batch * 256 * 13 * 13);</div><div class="line">    std::vector&lt;float&gt; user_dst(batch * 384 * 13 * 13);</div><div class="line"></div><div class="line">    <span class="comment">// Allocate and fill buffers for weights and bias</span></div><div class="line">    std::vector&lt;float&gt; conv_weights(product(conv_weights_tz));</div><div class="line">    std::vector&lt;float&gt; conv_bias(product(conv_bias_tz));</div><div class="line"></div><div class="line"><span class="comment">//[Allocate buffers]</span></div><div class="line">    <span class="keyword">auto</span> user_src_memory = <a name="_a5"></a><a class="code" href="structmkldnn_1_1memory.html">memory</a>({ { conv_src_tz }, dt::f32, tag::nchw },</div><div class="line">            cpu_engine, user_src.data());</div><div class="line">    <span class="keyword">auto</span> user_weights_memory</div><div class="line">            = <a class="code" href="structmkldnn_1_1memory.html">memory</a>({ { conv_weights_tz }, dt::f32, tag::oihw }, cpu_engine,</div><div class="line">                    conv_weights.data());</div><div class="line">    <span class="keyword">auto</span> user_bias_memory = <a class="code" href="structmkldnn_1_1memory.html">memory</a>({ { conv_bias_tz }, dt::f32, tag::x },</div><div class="line">            cpu_engine, conv_bias.data());</div><div class="line"><span class="comment">//[Allocate buffers]</span></div><div class="line"></div><div class="line"><span class="comment">//[Create convolution memory descriptors]</span></div><div class="line">    <span class="keyword">auto</span> conv_src_md = <a name="_a6"></a><a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ conv_src_tz }, dt::u8, tag::any);</div><div class="line">    <span class="keyword">auto</span> conv_bias_md = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ conv_bias_tz }, dt::s8, tag::any);</div><div class="line">    <span class="keyword">auto</span> conv_weights_md = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ conv_weights_tz }, dt::s8, tag::any);</div><div class="line">    <span class="keyword">auto</span> conv_dst_md = <a class="code" href="structmkldnn_1_1memory_1_1desc.html">memory::desc</a>({ conv_dst_tz }, dt::u8, tag::any);</div><div class="line"><span class="comment">//[Create convolution memory descriptors]</span></div><div class="line"></div><div class="line"><span class="comment">//[Create convolution descriptor]</span></div><div class="line">    <span class="keyword">auto</span> conv_desc = <a name="_a7"></a><a class="code" href="structmkldnn_1_1convolution__forward_1_1desc.html">convolution_forward::desc</a>(<a name="a8"></a><a class="code" href="group__cpp__api__enums.html#ggaeb087eae78f70a4d249a90aefa165cf8a965dbaac085fc891bfbbd4f9d145bbc8">prop_kind::forward</a>,</div><div class="line">            <a name="a9"></a><a class="code" href="group__cpp__api__enums.html#ggae45a07d6121fdd33e310782753178076a5028ad8f818a45333a8a0eefad35c5c0">algorithm::convolution_direct</a>, conv_src_md, conv_weights_md, conv_bias_md,</div><div class="line">            conv_dst_md, conv_strides, conv_padding, conv_padding);</div><div class="line"><span class="comment">//[Create convolution descriptor]</span></div><div class="line"></div><div class="line"><span class="comment">//[Configure scaling]</span></div><div class="line">    <a name="_a10"></a><a class="code" href="structmkldnn_1_1primitive__attr.html">primitive_attr</a> conv_attr;</div><div class="line">    conv_attr.<a name="a11"></a><a class="code" href="structmkldnn_1_1primitive__attr.html#a1c2ba432512cf9950b81febce265e35d">set_output_scales</a>(conv_mask, conv_scales);</div><div class="line"><span class="comment">//[Configure scaling]</span></div><div class="line"></div><div class="line"><span class="comment">//[Configure post-ops]</span></div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">float</span> ops_scale = 1.f;</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">float</span> ops_alpha = 0.f; <span class="comment">// relu negative slope</span></div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">float</span> ops_beta = 0.f;</div><div class="line">    <a name="_a12"></a><a class="code" href="structmkldnn_1_1post__ops.html">post_ops</a> ops;</div><div class="line">    ops.<a name="a13"></a><a class="code" href="structmkldnn_1_1post__ops.html#af86d191276edcc3bd16571dd357072ec">append_eltwise</a>(ops_scale, <a name="a14"></a><a class="code" href="group__cpp__api__enums.html#ggae45a07d6121fdd33e310782753178076aba09bebb742494255b90b43871c01c69">algorithm::eltwise_relu</a>, ops_alpha, ops_beta);</div><div class="line">    conv_attr.<a name="a15"></a><a class="code" href="structmkldnn_1_1primitive__attr.html#a4730acedb91c4cd93616bb69c3df90a7">set_post_ops</a>(ops);</div><div class="line"><span class="comment">//[Configure post-ops]</span></div><div class="line"></div><div class="line">    <span class="comment">// check if int8 convolution is supported</span></div><div class="line">    <span class="keywordflow">try</span> {</div><div class="line">        <span class="keyword">auto</span> conv_prim_desc = <a name="_a16"></a><a class="code" href="structmkldnn_1_1convolution__forward_1_1primitive__desc.html">convolution_forward::primitive_desc</a>(</div><div class="line">                conv_desc, conv_attr, cpu_engine);</div><div class="line">    } <span class="keywordflow">catch</span> (<a name="_a17"></a><a class="code" href="structmkldnn_1_1error.html">error</a> &amp;e) {</div><div class="line">        <span class="keywordflow">if</span> (e.<a name="a18"></a>status == <a name="a19"></a><a class="code" href="group__c__api__types__generic.html#gga31866789b66acfb1c28b2f9bdd7bdfdda253b1d7923a77456485a19734788b220">mkldnn_unimplemented</a>) {</div><div class="line">            std::cerr &lt;&lt; <span class="stringliteral">&quot;Intel MKL-DNN does not have int8 convolution &quot;</span></div><div class="line">            <span class="stringliteral">&quot;implementation that supports this system. Please refer to &quot;</span></div><div class="line">            <span class="stringliteral">&quot;the developer guide for details.&quot;</span> &lt;&lt; std::endl;</div><div class="line">        }</div><div class="line">        <span class="keywordflow">throw</span>;</div><div class="line">    }</div><div class="line"></div><div class="line"><span class="comment">//[Create convolution primitive descriptor]</span></div><div class="line">    <span class="keyword">auto</span> conv_prim_desc = <a class="code" href="structmkldnn_1_1convolution__forward_1_1primitive__desc.html">convolution_forward::primitive_desc</a>(</div><div class="line">            conv_desc, conv_attr, cpu_engine);</div><div class="line"><span class="comment">//[Create convolution primitive descriptor]</span></div><div class="line"></div><div class="line"><span class="comment">//[Quantize data and weights]</span></div><div class="line">    <span class="keyword">auto</span> conv_src_memory = <a class="code" href="structmkldnn_1_1memory.html">memory</a>(conv_prim_desc.src_desc(), cpu_engine);</div><div class="line">    <a class="code" href="structmkldnn_1_1primitive__attr.html">primitive_attr</a> src_attr;</div><div class="line">    src_attr.<a class="code" href="structmkldnn_1_1primitive__attr.html#a1c2ba432512cf9950b81febce265e35d">set_output_scales</a>(src_mask, src_scales);</div><div class="line">    <span class="keyword">auto</span> src_reorder_pd = reorder::primitive_desc(cpu_engine,</div><div class="line">            user_src_memory.get_desc(), cpu_engine,</div><div class="line">            conv_src_memory.get_desc(), src_attr);</div><div class="line">    <span class="keyword">auto</span> src_reorder = <a name="_a20"></a><a class="code" href="structmkldnn_1_1reorder.html">reorder</a>(src_reorder_pd);</div><div class="line">    src_reorder.execute(s, user_src_memory, conv_src_memory);</div><div class="line"></div><div class="line">    <span class="keyword">auto</span> conv_weights_memory</div><div class="line">            = <a class="code" href="structmkldnn_1_1memory.html">memory</a>(conv_prim_desc.weights_desc(), cpu_engine);</div><div class="line">    <a class="code" href="structmkldnn_1_1primitive__attr.html">primitive_attr</a> weight_attr;</div><div class="line">    weight_attr.<a class="code" href="structmkldnn_1_1primitive__attr.html#a1c2ba432512cf9950b81febce265e35d">set_output_scales</a>(weight_mask, weight_scales);</div><div class="line">    <span class="keyword">auto</span> weight_reorder_pd = reorder::primitive_desc(cpu_engine,</div><div class="line">            user_weights_memory.<a name="a21"></a><a class="code" href="structmkldnn_1_1memory.html#a5a8cc261a2925652c4b966d64a7d6136">get_desc</a>(), cpu_engine,</div><div class="line">            conv_weights_memory.get_desc(), weight_attr);</div><div class="line">    <span class="keyword">auto</span> weight_reorder = <a class="code" href="structmkldnn_1_1reorder.html">reorder</a>(weight_reorder_pd);</div><div class="line">    weight_reorder.execute(s, user_weights_memory, conv_weights_memory);</div><div class="line"></div><div class="line">    <span class="keyword">auto</span> conv_bias_memory = <a class="code" href="structmkldnn_1_1memory.html">memory</a>(conv_prim_desc.bias_desc(), cpu_engine);</div><div class="line">    <a class="code" href="structmkldnn_1_1primitive__attr.html">primitive_attr</a> bias_attr;</div><div class="line">    bias_attr.<a class="code" href="structmkldnn_1_1primitive__attr.html#a1c2ba432512cf9950b81febce265e35d">set_output_scales</a>(bias_mask, bias_scales);</div><div class="line">    <span class="keyword">auto</span> bias_reorder_pd = reorder::primitive_desc(cpu_engine,</div><div class="line">            user_bias_memory.<a class="code" href="structmkldnn_1_1memory.html#a5a8cc261a2925652c4b966d64a7d6136">get_desc</a>(), cpu_engine,</div><div class="line">            conv_bias_memory.get_desc(), bias_attr);</div><div class="line">    <span class="keyword">auto</span> bias_reorder = <a class="code" href="structmkldnn_1_1reorder.html">reorder</a>(bias_reorder_pd);</div><div class="line">    bias_reorder.execute(s, user_bias_memory, conv_bias_memory);</div><div class="line"><span class="comment">//[Quantize data and weights]</span></div><div class="line"></div><div class="line">    <span class="keyword">auto</span> conv_dst_memory = <a class="code" href="structmkldnn_1_1memory.html">memory</a>(conv_prim_desc.dst_desc(), cpu_engine);</div><div class="line"></div><div class="line"><span class="comment">//[Create convolution primitive]</span></div><div class="line">    <span class="keyword">auto</span> conv = <a name="_a22"></a><a class="code" href="structmkldnn_1_1convolution__forward.html">convolution_forward</a>(conv_prim_desc);</div><div class="line">    conv.execute(s,</div><div class="line">            { { MKLDNN_ARG_SRC, conv_src_memory },</div><div class="line">                    { MKLDNN_ARG_WEIGHTS, conv_weights_memory },</div><div class="line">                    { MKLDNN_ARG_BIAS, conv_bias_memory },</div><div class="line">                    { MKLDNN_ARG_DST, conv_dst_memory } });</div><div class="line"><span class="comment">//[Create convolution primitive]</span></div><div class="line"></div><div class="line"><span class="comment">//[Dequantize the result]</span></div><div class="line">    <span class="keyword">auto</span> user_dst_memory = <a class="code" href="structmkldnn_1_1memory.html">memory</a>({ { conv_dst_tz }, dt::f32, tag::nchw },</div><div class="line">            cpu_engine, user_dst.data());</div><div class="line">    <a class="code" href="structmkldnn_1_1primitive__attr.html">primitive_attr</a> dst_attr;</div><div class="line">    dst_attr.<a class="code" href="structmkldnn_1_1primitive__attr.html#a1c2ba432512cf9950b81febce265e35d">set_output_scales</a>(dst_mask, dst_scales);</div><div class="line">    <span class="keyword">auto</span> dst_reorder_pd = reorder::primitive_desc(cpu_engine,</div><div class="line">            conv_dst_memory.get_desc(), cpu_engine,</div><div class="line">            user_dst_memory.get_desc(), dst_attr);</div><div class="line">    <span class="keyword">auto</span> dst_reorder = <a class="code" href="structmkldnn_1_1reorder.html">reorder</a>(dst_reorder_pd);</div><div class="line">    dst_reorder.execute(s, conv_dst_memory, user_dst_memory);</div><div class="line"><span class="comment">//[Dequantize the result]</span></div><div class="line"></div><div class="line">    s.<a name="a23"></a><a class="code" href="structmkldnn_1_1stream.html#a48181ce0f5eb3bcd75778b5aa8866df6">wait</a>();</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keywordtype">int</span> main(<span class="keywordtype">int</span> argc, <span class="keywordtype">char</span> **argv) {</div><div class="line">    <span class="keywordflow">try</span> {</div><div class="line">        simple_net_int8();</div><div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Simple-net-int8 example passed!&quot;</span> &lt;&lt; std::endl;</div><div class="line">    } <span class="keywordflow">catch</span> (<a class="code" href="structmkldnn_1_1error.html">error</a> &amp;e) {</div><div class="line">        std::cerr &lt;&lt; <span class="stringliteral">&quot;status: &quot;</span> &lt;&lt; e.status &lt;&lt; std::endl;</div><div class="line">        std::cerr &lt;&lt; <span class="stringliteral">&quot;message: &quot;</span> &lt;&lt; e.<a name="a24"></a>message &lt;&lt; std::endl;</div><div class="line">    }</div><div class="line">    <span class="keywordflow">return</span> 0;</div><div class="line">}</div></div><!-- fragment --> </div><!-- contents -->
<div class="footer">
    <div class="footer-wrapper">
        <ul id="footer-links">
            <li><a href="legal_information.html">Legal information</a></li>
        </ul>
    </div>
</div>