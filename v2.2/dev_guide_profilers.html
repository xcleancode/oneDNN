<!-- HTML header for doxygen 1.8.5-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width,initial-scale=1.0">
<title>oneDNN: Profiling oneDNN Performance</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(initResizable);
/* @license-end */</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<script src="assets/mathjax/MathJax.js?config=TeX-AMS_CHTML,dnnl"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="assets/customdoxygen.css" rel="stylesheet" type="text/css" />
<script type="text/javascript" src="assets/dnn.js"></script>
</head>
<body>
<div class="mobile-nav"><i id="nav-btn"></i><a href="index.html">oneAPI Deep Neural Network Library (oneDNN)</a></div>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
   <div id="projectname">
     <a href="index.html">
      <div id="full-name">oneAPI Deep Neural Network Library (oneDNN)</div>
    </a>
   </div>
   <div id="projectbrief">Performance library for Deep Learning</div>
   <div id="projectnumber">2.2.4</div>
  <div>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
</div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('dev_guide_profilers.html','');});
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Profiling oneDNN Performance </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>oneDNN uses JIT (just-in-time) code generation based on the primitive parameters and instruction set supported by the system. In order to correctly attribute performance event information, profilers must be notified about address ranges containing JIT-ed code. oneDNN supports two profilers: VTune(TM) Amplifier and Linux perf.</p>
<h2>Build-Time Controls</h2>
<p>At build-time, support for this feature is controlled via cmake option <code>DNNL_ENABLE_JIT_PROFILING</code>.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadLeft">CMake Option  </th><th class="markdownTableHeadLeft">Supported values (defaults in bold)  </th><th class="markdownTableHeadLeft">Desc   </th></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">DNNL_ENABLE_JIT_PROFILING  </td><td class="markdownTableBodyLeft"><b>ON</b>, OFF  </td><td class="markdownTableBodyLeft">Enables performance profilers integration   </td></tr>
</table>
<h2>Run-Time Controls</h2>
<p>When the feature is enabled at build-time, the <code>DNNL_JIT_PROFILE</code> environment variable can be used to manage integration with performance profilers.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadLeft">Environment variable  </th><th class="markdownTableHeadLeft">Value  </th><th class="markdownTableHeadLeft">Description  </th><th class="markdownTableHeadLeft">x64  </th><th class="markdownTableHeadLeft">AArc   </th></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">DNNL_JIT_PROFILE  </td><td class="markdownTableBodyLeft">1  </td><td class="markdownTableBodyLeft">Enables VTune Amplifier integration  </td><td class="markdownTableBodyLeft"><b>x(default)</b>  </td><td class="markdownTableBodyLeft">N/A   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyLeft"></td><td class="markdownTableBodyLeft">2  </td><td class="markdownTableBodyLeft">Enables basic Linux perf integration  </td><td class="markdownTableBodyLeft">x  </td><td class="markdownTableBodyLeft"><b>x(default)</b>   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyLeft"></td><td class="markdownTableBodyLeft">6  </td><td class="markdownTableBodyLeft">Enables Linux perf integration with JIT dump output  </td><td class="markdownTableBodyLeft">x  </td><td class="markdownTableBodyLeft">x   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyLeft"></td><td class="markdownTableBodyLeft">14  </td><td class="markdownTableBodyLeft">Enables Linux perf integration with JIT dump output and TSC timestamps  </td><td class="markdownTableBodyLeft">x  </td><td class="markdownTableBodyLeft">N/A   </td></tr>
</table>
<p>Other valid values for <code>DNNL_JIT_PROFILE</code> include integer values representing a combination of flags accepted by the <a class="el" href="group__dnnl__api__service.html#ga51ef634e4f201a12d32e573955943f48">dnnl_set_jit_profiling_flags</a> function.</p>
<p>The default setting of the profiling flags is to enable integration with VTune Amplifier; therefore it does not require any additional setup and works out of the box. Code integrating oneDNN may override this behavior.</p>
<p>This feature can also be managed at run-time with the following functions:</p><ul>
<li><a class="el" href="group__dnnl__api__service.html#ga51ef634e4f201a12d32e573955943f48">dnnl_set_jit_profiling_flags</a></li>
<li><a class="el" href="group__dnnl__api__service.html#gafb0fb0d37d72bc58386ba97bb858f8f7">dnnl_set_jit_profiling_jitdumpdir</a></li>
</ul>
<p>Function settings take precedence over environment variables.</p>
<h3>Features for VTune Amplifier</h3>
<h4>ITT Tagging for Primitive Execution</h4>
<p>oneDNN supports ITT tagging at primitive execution in order to provide performance information on the level of a oneDNN primitive. This feature is supported on both CPU and GPU.</p>
<p>ITT tagging in oneDNN during primitive execution provides more information from VTune Amplifier for the items below.</p><ol type="1">
<li>Get the primitives timeline chart from VTune Amplifier, and identify potential performance issues.</li>
<li>Get platform information such as an L1/L2 cache miss or level of FP vectorization on the primitive level.</li>
<li>Map primitive with related computation kernels.</li>
</ol>
<h5>Build-Time Controls</h5>
<p>At build-time, support for this feature is controlled via cmake option <code>DNNL_ENABLE_JIT_PROFILING</code>.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadLeft">CMake Option  </th><th class="markdownTableHeadLeft">Supported values (defaults in bold)  </th><th class="markdownTableHeadLeft">Desc   </th></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">DNNL_ENABLE_ITT_TASKS  </td><td class="markdownTableBodyLeft"><b>ON</b>, OFF  </td><td class="markdownTableBodyLeft">Enables ITT tagging for primitive execution   </td></tr>
</table>
<h5>Run-Time Controls</h5>
<p>When the feature is enabled at build-time, the <code>DNNL_ITT_TASK_LEVEL</code> environment variable can be used to enable different level of ITT tagging.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadLeft">Environment variable  </th><th class="markdownTableHeadLeft">Value  </th><th class="markdownTableHeadLeft">Desc   </th></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">DNNL_ITT_TASK_LEVEL  </td><td class="markdownTableBodyLeft">0  </td><td class="markdownTableBodyLeft">no ITT event will be triggered   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyLeft"></td><td class="markdownTableBodyLeft">1  </td><td class="markdownTableBodyLeft">ITT events are only triggered in master thread   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyLeft"></td><td class="markdownTableBodyLeft"><b>2</b>  </td><td class="markdownTableBodyLeft"><b>ITT events are triggered in all OMP/TBB threads</b>   </td></tr>
</table>
<h2>Example: Profiling with VTune Amplifier</h2>
<p>For this section, it is assumed that the performance profiling environment is already set up.</p>
<h3>profiling for hotspots</h3>
<p>Collect profiling data:</p>
<div class="fragment"><div class="line">$ amplxe-cl -collect hotspots -q -no-summary -knob sampling-mode=hw -r dnnl-vtune ./benchdnn --mode=P --conv --batch=inputs/conv/shapes_alexnet</div><div class="line">amplxe: Warning: To enable hardware event-base sampling, VTune Amplifier has disabled the NMI watchdog timer.  </div><div class="line">The watchdog timer will be re-enabled after collection completes.</div><div class="line">Output template: perf,%engine%,%impl%,%name%,%prb%,%Gops%,%Gfreq%,%-time%,%-Gflops%,%0time%,%0Gflops%</div><div class="line">perf,cpu,jit:avx512_common,&quot;alexnet:conv1&quot;,--conv g1mb256ic3ih227oc96oh55kh11sh4ph0n&quot;alexnet:conv1&quot;,53.9726,0,17.4285,3096.81,22.5851,2389.74</div><div class="line">perf,cpu,jit:avx512_common,&quot;alexnet:conv2&quot;,--conv g2mb256ic96ih27oc256oh27kh5ph2n&quot;alexnet:conv2&quot;,104.696,0,20.2195,5177.98,21.9233,4775.56</div><div class="line">perf,cpu,jit:avx512_common,&quot;alexnet:conv3&quot;,--conv mb256ic256ih13oc384oh13kh3ph1n&quot;alexnet:conv3&quot;,68.904,0,15.5134,4441.57,18.1391,3798.64</div><div class="line">perf,cpu,jit:avx512_common,&quot;alexnet:conv4&quot;,--conv g2mb256ic384ih13oc384oh13kh3ph1n&quot;alexnet:conv4&quot;,51.678,0,11.7397,4401.97,12.4623,4146.76</div><div class="line">perf,cpu,jit:avx512_common,&quot;alexnet:conv5&quot;,--conv g2mb256ic384ih13oc256oh13kh3ph1n&quot;alexnet:conv5&quot;,34.452,0,7.77148,4433.13,8.50435,4051.11</div><div class="line">tests:5 passed:5 skipped:0 mistrusted:0 unimplemented:0 failed:0 listed:0</div><div class="line">total perf: min(ms):72.6726 avg(ms):83.6142</div></div><!-- fragment --><dl class="section note"><dt>Note</dt><dd>Here, it is not necessary to set the <code>DNNL_JIT_PROFILE</code> environment variable.</dd></dl>
<p>Below are the top 10 function hotspots using the command-line interface:</p>
<div class="fragment"><div class="line">$ amplxe-cl -report hotspots -q -r dnnl-vtune -format csv -csv-delimiter &#39;;&#39; -group-by process,module,function -column &#39;CPU Time:Self&#39; | head -n 10 | column -t -s&#39;;&#39;</div><div class="line">Column filter is ON.</div><div class="line">Process   Module            Function                               CPU Time</div><div class="line">benchdnn  [Dynamic code]    _jit_avx512_common_conv_fwd_kernel     300.128503</div><div class="line">benchdnn  [Dynamic code]    _jit_avx512_common_conv_fwd_kernel     293.946143</div><div class="line">benchdnn  [Dynamic code]    _jit_avx512_common_conv_fwd_kernel     285.549830</div><div class="line">benchdnn  [Dynamic code]    _jit_avx512_common_conv_fwd_kernel     268.868599</div><div class="line">benchdnn  [Dynamic code]    _jit_avx512_common_conv_fwd_kernel     256.715527</div><div class="line">benchdnn  libgomp.so.1.0.0  func@0x194f0                           186.604226</div><div class="line">benchdnn  libgomp.so.1.0.0  func@0x19370                           82.609694</div><div class="line">benchdnn  libdnnl.so.1.8    dnnl::impl::cpu::x64::jit_avx512_co..  35.682241</div><div class="line">benchdnn  vmlinux           [vmlinux]                                                                                                                                                                                                          10.763433</div></div><!-- fragment --><p>The JIT-ed function <code>_jit_avx512_common_conv_fwd_kernel</code> is shown as belonging to the <code>[Dynamic code]</code> module.</p>
<p>Below are the top 10 primitive type hotspots using the command-line interface:</p>
<div class="fragment"><div class="line">$ amplxe-cl -report hotspots -q -r dnnl-vtune -format csv -csv-delimiter &#39;;&#39; -group-by task -column &#39;CPU Time:Self&#39; | head -n 10 | column -t -s&#39;;&#39;</div><div class="line">Column filter is ON.</div><div class="line">Task Type           CPU Time</div><div class="line">convolution         1451.459338</div><div class="line">[Outside any task]  280.489764</div><div class="line">reorder             10.434821                                                                                                                                                                                             10.763433</div></div><!-- fragment --><h3>Profiling for Micro-architecture Information</h3>
<p>Collect profiling data:</p>
<div class="fragment"><div class="line">$ amplxe-cl -collect uarch-exploration -knob sampling-interval=1 -data-limit=2000  -q -no-summary -r dnnl-vtune-ue ./benchdnn --mode=P --conv --batch=inputs/conv/shapes_alexnet </div><div class="line">amplxe: Warning: To enable hardware event-base sampling, VTune Amplifier has disabled the NMI watchdog timer. The watchdog timer will be re-enabled after collection completes.</div><div class="line">Output template: perf,%engine%,%impl%,%name%,%prb%,%Gops%,%Gfreq%,%-time%,%-Gflops%,%0time%,%0Gflops%</div><div class="line">perf,cpu,jit:avx512_common,&quot;alexnet:conv1&quot;,--conv g1mb256ic3ih227oc96oh55kh11sh4ph0n&quot;alexnet:conv1&quot;,53.9726,0,17.2344,3131.68,24.1246,2237.24</div><div class="line">perf,cpu,jit:avx512_common,&quot;alexnet:conv2&quot;,--conv g2mb256ic96ih27oc256oh27kh5ph2n&quot;alexnet:conv2&quot;,104.696,0,20.2988,5157.74,22.6731,4617.63</div><div class="line">perf,cpu,jit:avx512_common,&quot;alexnet:conv3&quot;,--conv mb256ic256ih13oc384oh13kh3ph1n&quot;alexnet:conv3&quot;,68.904,0,15.5369,4434.87,17.1371,4020.75</div><div class="line">perf,cpu,jit:avx512_common,&quot;alexnet:conv4&quot;,--conv g2mb256ic384ih13oc384oh13kh3ph1n&quot;alexnet:conv4&quot;,51.678,0,11.428,4522.06,12.7986,4037.79</div><div class="line">perf,cpu,jit:avx512_common,&quot;alexnet:conv5&quot;,--conv g2mb256ic384ih13oc256oh13kh3ph1n&quot;alexnet:conv5&quot;,34.452,0,7.64233,4508.05,8.99841,3828.68</div><div class="line">tests:5 passed:5 skipped:0 mistrusted:0 unimplemented:0 failed:0 listed:0</div><div class="line">total perf: min(ms):72.1404 avg(ms):85.7318</div></div><!-- fragment --><p>Below are L1 Data Cache issues among primitive types using the command-line interface:</p>
<div class="fragment"><div class="line">$ amplxe-cl -report hotspots -q -r dnnl-vtune-ue -format csv -csv-delimiter &#39;;&#39; -group-by task -column &#39;L1 Bound&#39; | head -n 10 | column -t -s&#39;;&#39;</div><div class="line">Column filter is ON.</div><div class="line">Task Type           Back-End Bound:Memory Bound:L1 Bound(%)  Back-End Bound:Memory Bound:L1 Bound:DTLB Overhead(%)  Back-End Bound:Memory Bound:L1 Bound:Loads Blocked by Store Forwarding(%)  Back-End Bound:Memory Bound:L1 Bound:Lock Latency(%)  Back-End Bound:Memory Bound:L1 Bound:Split Loads(%)  Back-End Bound:Memory Bound:L1 Bound:4K Aliasing(%)  Back-End Bound:Memory Bound:L1 Bound:FB Full(%)</div><div class="line">convolution         8.2                                      0.0                                                    0.0                                                                        0.0                                                   0.0                                                  0.2                                                  26.6</div><div class="line">[Outside any task]  4.4                                      0.0                                                    0.0                                                                        0.0                                                   0.0                                                  0.0                                                  2.6</div><div class="line">reorder             16.0                                     0.0                                                    0.0                                                                        0.0                                                   0.0                                                  0.1 </div></div><!-- fragment --><p>Below are issues with Instruction Cache misses among primitive types using the command-line interface:</p>
<div class="fragment"><div class="line">$ amplxe-cl -report hotspots -q -r dnnl-vtune-ue -format csv -csv-delimiter &#39;;&#39; -group-by task -column &#39;ICache Misses&#39; | head -n 10 | column -t -s&#39;;&#39;</div><div class="line">Column filter is ON.</div><div class="line">Task Type           Front-End Bound:Front-End Latency:ICache Misses(%)</div><div class="line">convolution         0.2</div><div class="line">[Outside any task]  0.1</div><div class="line">reorder             0.3</div></div><!-- fragment --><p>Here are some column names within micro-architecture profiling results. You could replace 'ICache Misses' with another column name.</p>
<p>*"ICache Misses","ITLB Overhead","Bad Speculation","L1 Bound","L2 Bound","L3 Bound","DRAM Bound","Average CPU Frequency","Task Time","Task Count", etc*</p>
<p>For getting all column names within your profiling results, you could use the command below to get more detailed information. </p><div class="fragment"><div class="line">$ amplxe-cl -report hotspots -q -r dnnl-vtune-ue -format csv -csv-delimiter &#39;;&#39; -group-by task -column=?</div><div class="line">Available values for &#39;-column&#39; option are:</div><div class="line">CPU Time:Self</div><div class="line">Clockticks:Self</div><div class="line">Instructions Retired:Self</div><div class="line">CPI Rate:Self</div><div class="line">Retiring:Self</div><div class="line">Retiring:General Retirement:Self</div><div class="line">Retiring:General Retirement:FP Arithmetic:Self</div><div class="line">Retiring:General Retirement:FP Arithmetic:FP x87:Self</div><div class="line">Retiring:General Retirement:FP Arithmetic:FP Scalar:Self</div><div class="line">Retiring:General Retirement:FP Arithmetic:FP Vector:Self</div><div class="line">Retiring:General Retirement:Other:Self</div><div class="line">Retiring:Microcode Sequencer:Self</div><div class="line">Retiring:Microcode Sequencer:Assists:Self</div><div class="line">Front-End Bound:Self</div><div class="line">Front-End Bound:Front-End Latency:Self</div><div class="line">Front-End Bound:Front-End Latency:ICache Misses:Self</div></div><!-- fragment --><p>See more examples in the <a href="https://software.intel.com/content/www/us/en/develop/documentation/vtune-help/top/introduction/tutorials-and-samples.html">VTune Amplifier User Guide</a></p>
<h2>Example: Profiling with Linux perf</h2>
<p>The following command instructs oneDNN to enable both jitdump and perfmap profiling modes and write jitdump files into the <code>.debug</code> directory in the current directory by setting environment variable <code>JITDUMPDIR</code> to point to the current directory.</p>
<div class="fragment"><div class="line">$ JITDUMPDIR=. DNNL_JIT_PROFILE=6 perf record -k1 ./tests/benchdnn/benchdnn --conv --mode=P mb1ic32ih14oc32oh14kh3ph1n&quot;resnet_50:res4a_branch2b*6&quot;</div><div class="line">Output template: perf,%engine%,%name%,%desc%,%Gops%,%Gfreq%,%-time%,%-Gflops%,%0time%,%0Gflops%</div><div class="line">perf,cpu,resnet_50:res4a_branch2b*6,--conv mb1ic32ih14oc32oh14kh3ph1nresnet_50:res4a_branch2b*6,0.0032768,0,0.0131836,248.551,0.0262988,124.599</div><div class="line">tests:1 passed:0 skipped:0 mistrusted:0 unimplemented:0 failed:0 listed:0</div><div class="line">total perf: min(ms):0.0131836 avg(ms):0.0262988</div><div class="line">[ perf record: Woken up 1 times to write data ]</div><div class="line">[ perf record: Captured and wrote 0.884 MB perf.data (23102 samples) ]</div></div><!-- fragment --><p>The following command injects the information from the jitdump files into the performance data: </p><div class="fragment"><div class="line">$ perf inject -j -i perf.data -o perf.data.j</div></div><!-- fragment --><p>The following command displays the top hotspots: </p><div class="fragment"><div class="line">$ perf report -i perf.data.j --stdio | head -n20</div><div class="line"># To display the perf.data header info, please use --header/--header-only options.</div><div class="line">#</div><div class="line">#</div><div class="line"># Total Lost Samples: 0</div><div class="line">#</div><div class="line"># Samples: 23K of event &#39;cpu-clock:uhH&#39;</div><div class="line"># Event count (approx.): 5775500000</div><div class="line">#</div><div class="line"># Overhead  Command   Shared Object        Symbol</div><div class="line">#</div><div class="line">    39.33%  benchdnn  libgomp.so.1.0.0     [.] 0x000000000001d8ba</div><div class="line">    29.41%  benchdnn  jitted-31475-0.so    [.] jit_avx2_conv_fwd_kernel_f32</div><div class="line">    20.49%  benchdnn  libgomp.so.1.0.0     [.] 0x000000000001d712</div><div class="line">     3.47%  benchdnn  libdnnl.so.1.1       [.] dnnl::impl::cpu::jit_avx2_convolution_fwd_t::execute_forward(dnnl::impl::exec_ctx_t const&amp;) const::{lambda(int, int)#1}::operator()</div><div class="line">     1.52%  benchdnn  libgomp.so.1.0.0     [.] 0x000000000001d8be</div><div class="line">     0.93%  benchdnn  libgomp.so.1.0.0     [.] 0x000000000001d716</div><div class="line">     0.75%  benchdnn  libgomp.so.1.0.0     [.] 0x000000000001d8c5</div><div class="line">     0.55%  benchdnn  libgomp.so.1.0.0     [.] 0x000000000001d8c3</div><div class="line">     0.46%  benchdnn  libgomp.so.1.0.0     [.] 0x000000000001d71d</div></div><!-- fragment --><dl class="section note"><dt>Note</dt><dd>Not every kernel/distribution supports displaying detailed profiling information. Symbol resolution (usually) works as long as the perfmap mode is enabled, but annotating a JIT-ed functions disassembly, which requires jitdump, seems to often fail on kernels before 5.x.</dd></dl>
<p>See more on <a href="http://www.brendangregg.com/perf.html">Brendan Gregg's excellent perf examples page</a> </p>
</div></div><!-- contents -->
</div><!-- doc-content -->
<div class="footer">
    <script>
        $('#top').prependTo($('#side-nav'));
    </script>
    <div class="footer-wrapper">
        <hr>
        <ul class="footer-links">
            <li><a href="legal_information.html">Legal information</a></li>
        </ul>
    </div>
</div>