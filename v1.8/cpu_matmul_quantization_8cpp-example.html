<!-- HTML header for doxygen 1.8.5-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width,initial-scale=1.0">
<title>oneDNN: cpu_matmul_quantization.cpp</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(initResizable);
/* @license-end */</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<script src="assets/mathjax/MathJax.js?config=TeX-AMS_CHTML,dnnl"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="assets/customdoxygen.css" rel="stylesheet" type="text/css" />
<script type="text/javascript" src="assets/dnn.js"></script>
</head>
<body>
<div class="mobile-nav"><i id="nav-btn"></i><a href="index.html">oneAPI Deep Neural Network Library (oneDNN)</a></div>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
   <div id="projectname">
     <a href="index.html">
      <div id="full-name">oneAPI Deep Neural Network Library (oneDNN)</div>
    </a>
   </div>
   <div id="projectbrief">Performance library for Deep Learning</div>
   <div id="projectnumber">1.8.0</div>
  <div>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
</div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('cpu_matmul_quantization_8cpp-example.html','');});
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">cpu_matmul_quantization.cpp</div>  </div>
</div><!--header-->
<div class="contents">
<blockquote class="doxtable">
<p>Annotated version: <a class="el" href="cpu_matmul_quantization_cpp.html">MatMul Tutorial: Quantization</a></p>
</blockquote>
<div class="fragment"><div class="line"><span class="comment">/*******************************************************************************</span></div><div class="line"><span class="comment">* Copyright 2019-2020 Intel Corporation</span></div><div class="line"><span class="comment">*</span></div><div class="line"><span class="comment">* Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></div><div class="line"><span class="comment">* you may not use this file except in compliance with the License.</span></div><div class="line"><span class="comment">* You may obtain a copy of the License at</span></div><div class="line"><span class="comment">*</span></div><div class="line"><span class="comment">*     http://www.apache.org/licenses/LICENSE-2.0</span></div><div class="line"><span class="comment">*</span></div><div class="line"><span class="comment">* Unless required by applicable law or agreed to in writing, software</span></div><div class="line"><span class="comment">* distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></div><div class="line"><span class="comment">* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></div><div class="line"><span class="comment">* See the License for the specific language governing permissions and</span></div><div class="line"><span class="comment">* limitations under the License.</span></div><div class="line"><span class="comment">*******************************************************************************/</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="preprocessor">#include &lt;cassert&gt;</span></div><div class="line"><span class="preprocessor">#include &lt;cctype&gt;</span></div><div class="line"><span class="preprocessor">#include &lt;cmath&gt;</span></div><div class="line"><span class="preprocessor">#include &lt;cstdio&gt;</span></div><div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div><div class="line"><span class="preprocessor">#include &lt;random&gt;</span></div><div class="line"><span class="preprocessor">#include &lt;stdexcept&gt;</span></div><div class="line"><span class="preprocessor">#include &lt;vector&gt;</span></div><div class="line"><span class="preprocessor">#include &lt;type_traits&gt;</span></div><div class="line"></div><div class="line"><span class="preprocessor">#include &quot;<a class="code" href="dnnl_8hpp.html">dnnl.hpp</a>&quot;</span></div><div class="line"></div><div class="line"><span class="preprocessor">#include &quot;example_utils.hpp&quot;</span></div><div class="line"></div><div class="line"><span class="keyword">using namespace </span><a class="code" href="namespacednnl.html">dnnl</a>;</div><div class="line"></div><div class="line"><span class="keyword">enum class</span> q10n_scheme_t { DYNAMIC, STATIC };</div><div class="line"></div><div class="line"><span class="keyword">namespace </span>{</div><div class="line"></div><div class="line"><span class="keywordtype">void</span> init_vector(std::vector&lt;float&gt; &amp;v, <span class="keywordtype">float</span> min_value, <span class="keywordtype">float</span> max_value) {</div><div class="line">    std::mt19937 gen;</div><div class="line">    std::uniform_real_distribution&lt;float&gt; u(min_value, max_value);</div><div class="line"></div><div class="line">    <span class="keywordflow">for</span> (<span class="keyword">auto</span> &amp;e : v)</div><div class="line">        e = u(gen);</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div><div class="line"><span class="keywordtype">void</span> find_min_max(<span class="keyword">const</span> std::vector&lt;T&gt; &amp;v, <span class="keywordtype">float</span> &amp;min_value, <span class="keywordtype">float</span> &amp;max_value) {</div><div class="line">    min_value = max_value = v[0];</div><div class="line">    <span class="keywordflow">for</span> (<span class="keyword">auto</span> &amp;e : v) {</div><div class="line">        min_value = std::min&lt;float&gt;(min_value, e);</div><div class="line">        max_value = std::max&lt;float&gt;(max_value, e);</div><div class="line">    }</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div><div class="line"><span class="keywordtype">void</span> compute_q10n_params(<span class="keyword">const</span> <span class="keywordtype">char</span> *message, <span class="keyword">const</span> std::vector&lt;float&gt; &amp;v,</div><div class="line">        <span class="keywordtype">float</span> &amp;scale, int32_t &amp;zp) {</div><div class="line">    <span class="comment">// Find property of T integer type</span></div><div class="line">    <span class="comment">// Simple trick to improve accuracy: shrink the range a little bit</span></div><div class="line">    <span class="keywordtype">float</span> max_int = (float)std::numeric_limits&lt;T&gt;::max() - 1;</div><div class="line">    <span class="keywordtype">float</span> min_int = (float)std::numeric_limits&lt;T&gt;::lowest() + 1;</div><div class="line"></div><div class="line"><span class="preprocessor">#ifndef OMIT_WORKAROUND_FOR_SKX</span></div><div class="line">    <span class="comment">// Read more in CPU / Section 1 here:</span></div><div class="line">    <span class="comment">// https://oneapi-src.github.io/oneDNN/dev_guide_int8_computations.html</span></div><div class="line">    <span class="keywordflow">if</span> (std::is_same&lt;T, uint8_t&gt;::value) max_int /= 2;</div><div class="line"><span class="preprocessor">#endif</span></div><div class="line"></div><div class="line">    <span class="comment">// Find min and max value in array</span></div><div class="line">    <span class="keywordtype">float</span> min_val = v[0], max_val = v[0];</div><div class="line">    find_min_max(v, min_val, max_val);</div><div class="line"></div><div class="line">    <span class="comment">// Compute appropriate scale</span></div><div class="line">    scale = (max_val - min_val) / (max_int - min_int);</div><div class="line"></div><div class="line">    <span class="comment">// Compute appropriate offset</span></div><div class="line">    <span class="keywordflow">if</span> (std::is_same&lt;T, int8_t&gt;::value)</div><div class="line">        zp = 0;</div><div class="line">    <span class="keywordflow">else</span></div><div class="line">        zp = (int32_t)(max_int - max_val / scale);</div><div class="line">    printf(<span class="stringliteral">&quot;\tComputing q10n params for %s\n&quot;</span></div><div class="line">           <span class="stringliteral">&quot;\t\tData type: %s\n&quot;</span></div><div class="line">           <span class="stringliteral">&quot;\t\tScale:%.3g (inverse scale:%.3g)\n&quot;</span></div><div class="line">           <span class="stringliteral">&quot;\t\tZero point:%d\n\n&quot;</span>,</div><div class="line">            message, std::is_same&lt;T, int8_t&gt;::value ? <span class="stringliteral">&quot;int8_t&quot;</span> : <span class="stringliteral">&quot;uint8_t&quot;</span>,</div><div class="line">            scale, 1 / scale, zp);</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keywordtype">int</span> compare_vectors(<span class="keyword">const</span> std::vector&lt;float&gt; &amp;v1,</div><div class="line">        <span class="keyword">const</span> std::vector&lt;uint8_t&gt; &amp;v2, <span class="keywordtype">float</span> scale_v2, int32_t zp_v2,</div><div class="line">        <span class="keywordtype">float</span> threshold) {</div><div class="line">    <span class="keywordtype">double</span> v1_l2 = 0, diff_l2 = 0;</div><div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> n = 0; n &lt; v1.size(); ++n) {</div><div class="line">        <span class="keywordtype">float</span> v2_n = scale_v2 * (v2[n] - zp_v2); <span class="comment">// deq10n v2</span></div><div class="line">        <span class="keywordtype">float</span> diff = v1[n] - v2_n;</div><div class="line">        v1_l2 += v1[n] * v1[n];</div><div class="line">        diff_l2 += diff * diff;</div><div class="line">    }</div><div class="line"></div><div class="line">    v1_l2 = std::sqrt(v1_l2);</div><div class="line">    diff_l2 = std::sqrt(diff_l2);</div><div class="line">    <span class="keywordtype">bool</span> ok = diff_l2 &lt;= threshold * v1_l2;</div><div class="line"></div><div class="line">    printf(<span class="stringliteral">&quot;\tComparison (using l2-norms)\n&quot;</span></div><div class="line">           <span class="stringliteral">&quot;\t\tReference matrix:%g\n\t\tError:%g\n\t\tRelative error:%g\n&quot;</span></div><div class="line">           <span class="stringliteral">&quot;\nAccuracy check: %s\n\n&quot;</span>,</div><div class="line">            v1_l2, diff_l2, diff_l2 / v1_l2, ok ? <span class="stringliteral">&quot;OK&quot;</span> : <span class="stringliteral">&quot;FAILED&quot;</span>);</div><div class="line"></div><div class="line">    <span class="keywordflow">return</span> ok ? 0 : 1;</div><div class="line">}</div><div class="line"></div><div class="line">} <span class="comment">// namespace</span></div><div class="line"></div><div class="line"><a name="_a0"></a><a class="code" href="structdnnl_1_1engine.html">engine</a> eng(<a name="a1"></a><a class="code" href="structdnnl_1_1engine.html#a2635da16314dcbdb9bd9ea431316bb1aad9747e2da342bdb995f6389533ad1a3d">engine::kind::cpu</a>, 0); <span class="comment">// We create a global engine for simplicity</span></div><div class="line"></div><div class="line"><span class="comment">// Quantize float data into X_int_m oneDNN memory using the q10n parameters</span></div><div class="line"><span class="comment">//</span></div><div class="line"><span class="comment">// Inputs:</span></div><div class="line"><span class="comment">// - X_f32 -- source f32 matrix</span></div><div class="line"><span class="comment">// - scale_X, zp_X -- quantization parameters</span></div><div class="line"><span class="comment">// - q10n_scheme -- dynamic or static, to mimic real-world applications wrt to</span></div><div class="line"><span class="comment">//                  how the q10n parameters are passed to reorders</span></div><div class="line"><span class="comment">// Outputs:</span></div><div class="line"><span class="comment">// - X_int_m -- prepared oneDNN memory that would hold quantized values</span></div><div class="line"><span class="keywordtype">void</span> quantize(q10n_scheme_t q10n_scheme, <span class="keyword">const</span> std::vector&lt;float&gt; &amp;X_f32,</div><div class="line">        <span class="keywordtype">float</span> scale_X, int32_t zp_X, <a name="_a2"></a><a class="code" href="structdnnl_1_1memory.html">memory</a> &amp;X_int_m) {</div><div class="line">    <span class="keyword">using</span> <a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dce">dt</a> = <a name="a3"></a><a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dce">memory::data_type</a>;</div><div class="line"></div><div class="line">    <span class="comment">// Depending on `q10n_scheme` pretend the values come at run-time (dynamic)</span></div><div class="line">    <span class="comment">// or were known at creation time (static).</span></div><div class="line">    <span class="keywordtype">float</span> inv_scale_X = 1.f / scale_X;</div><div class="line"></div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">bool</span> is_dynamic_q10n = q10n_scheme == q10n_scheme_t::DYNAMIC;</div><div class="line"></div><div class="line">    <a name="_a4"></a><a class="code" href="structdnnl_1_1stream.html">stream</a> s(eng);</div><div class="line"></div><div class="line">    <a name="_a5"></a><a class="code" href="structdnnl_1_1memory_1_1desc.html">memory::desc</a> x_int_md = X_int_m.<a name="a6"></a><a class="code" href="structdnnl_1_1memory.html#ad8a1ad28ed7acf9c34c69e4b882c6e92">get_desc</a>();</div><div class="line">    <span class="keyword">const</span> <span class="keyword">auto</span> &amp;dims = x_int_md.<a name="a7"></a><a class="code" href="structdnnl_1_1memory_1_1desc.html#afea646e8777c2341509a61f4ae17dcf3">data</a>.<a name="a8"></a><a class="code" href="structdnnl__memory__desc__t.html#a47052ab197c58af737ac2865796402ce">dims</a>;</div><div class="line"></div><div class="line">    <a class="code" href="structdnnl_1_1memory_1_1desc.html">memory::desc</a> x_f32_md({dims[0], dims[1]}, dt::f32, {dims[1], 1});</div><div class="line">    <a class="code" href="structdnnl_1_1memory.html">memory</a> X_f32_m(x_f32_md, eng, (<span class="keywordtype">void</span> *)X_f32.data());</div><div class="line"></div><div class="line">    <a name="_a9"></a><a class="code" href="structdnnl_1_1primitive__attr.html">primitive_attr</a> q10n_attr;</div><div class="line">    q10n_attr.<a name="a10"></a><a class="code" href="structdnnl_1_1primitive__attr.html#a4b81acc8e48886313154f75c1708ae02">set_output_scales</a>(<span class="comment">/* mask */</span> 0,</div><div class="line">            {is_dynamic_q10n ? <a name="a11"></a><a class="code" href="group__dnnl__api__memory.html#gab16365c11b4dc88fbb453edb51f1979f">DNNL_RUNTIME_F32_VAL</a> : inv_scale_X});</div><div class="line">    q10n_attr.set_zero_points(<a name="a12"></a><a class="code" href="group__dnnl__api__primitives__common.html#ga3ca217e4a06d42a0ede3c018383c388f">DNNL_ARG_DST</a>, <span class="comment">/* mask */</span> 0,</div><div class="line">            {is_dynamic_q10n ? <a name="a13"></a><a class="code" href="group__dnnl__api__memory.html#ga30139d5110e9e895ccd93fe503ca4c35">DNNL_RUNTIME_S32_VAL</a> : zp_X});</div><div class="line"></div><div class="line">    <a name="_a14"></a><a class="code" href="structdnnl_1_1reorder_1_1primitive__desc.html">reorder::primitive_desc</a> q10n_pd(eng, x_f32_md, eng, x_int_md, q10n_attr);</div><div class="line">    <span class="keywordflow">if</span> (is_dynamic_q10n) {</div><div class="line">        <a class="code" href="structdnnl_1_1memory.html">memory</a> scale_X_m({{1}, dt::f32, {1}}, eng, &amp;inv_scale_X);</div><div class="line">        <a class="code" href="structdnnl_1_1memory.html">memory</a> zp_X_m({{1}, dt::s32, {1}}, eng, &amp;zp_X);</div><div class="line">        <a name="_a15"></a><a class="code" href="structdnnl_1_1reorder.html">reorder</a>(q10n_pd).<a name="a16"></a><a class="code" href="structdnnl_1_1reorder.html#ab9d5265274a13d4afa1fe33d784a1027">execute</a>(s,</div><div class="line">                {{<a name="a17"></a><a class="code" href="group__dnnl__api__primitives__common.html#gac37ad67b48edeb9e742af0e50b70fe09">DNNL_ARG_SRC</a>, X_f32_m}, {<a class="code" href="group__dnnl__api__primitives__common.html#ga3ca217e4a06d42a0ede3c018383c388f">DNNL_ARG_DST</a>, X_int_m},</div><div class="line">                        {<a name="a18"></a><a class="code" href="group__dnnl__api__primitives__common.html#ga0afb48b0c2b8f3ee30609aaa47aa29db">DNNL_ARG_ATTR_OUTPUT_SCALES</a>, scale_X_m},</div><div class="line">                        {<a name="a19"></a><a class="code" href="group__dnnl__api__primitives__common.html#gaf8d879adfe2baa2f9f2a5143a0f274b6">DNNL_ARG_ATTR_ZERO_POINTS</a> | <a class="code" href="group__dnnl__api__primitives__common.html#ga3ca217e4a06d42a0ede3c018383c388f">DNNL_ARG_DST</a>, zp_X_m}});</div><div class="line">    } <span class="keywordflow">else</span> {</div><div class="line">        <a class="code" href="structdnnl_1_1reorder.html">reorder</a>(q10n_pd).<a class="code" href="structdnnl_1_1reorder.html#ab9d5265274a13d4afa1fe33d784a1027">execute</a>(</div><div class="line">                s, {{<a class="code" href="group__dnnl__api__primitives__common.html#gac37ad67b48edeb9e742af0e50b70fe09">DNNL_ARG_SRC</a>, X_f32_m}, {<a class="code" href="group__dnnl__api__primitives__common.html#ga3ca217e4a06d42a0ede3c018383c388f">DNNL_ARG_DST</a>, X_int_m}});</div><div class="line">    }</div><div class="line"></div><div class="line">    s.wait();</div><div class="line">}</div><div class="line"></div><div class="line"><span class="comment">// Floating point MatMul</span></div><div class="line"><span class="comment">// Inputs:</span></div><div class="line"><span class="comment">// - Shape: M, N, K</span></div><div class="line"><span class="comment">// - Matrices A and B</span></div><div class="line"><span class="comment">// Outputs:</span></div><div class="line"><span class="comment">// - Matrix C</span></div><div class="line"><span class="keywordtype">void</span> f32_matmul_compute(int64_t M, int64_t N, int64_t K,</div><div class="line">        <span class="keyword">const</span> std::vector&lt;float&gt; &amp;A_f32, <span class="keyword">const</span> std::vector&lt;float&gt; &amp;B_f32,</div><div class="line">        std::vector&lt;float&gt; &amp;C_f32) {</div><div class="line">    <span class="comment">// Initialize memory descriptors that describes matrices in Row-Major format</span></div><div class="line">    <a class="code" href="structdnnl_1_1memory_1_1desc.html">memory::desc</a> a_md({M, K}, <a name="a20"></a><a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dcea512dc597be7ae761876315165dc8bd2e">memory::data_type::f32</a>, {K, 1});</div><div class="line">    <a class="code" href="structdnnl_1_1memory_1_1desc.html">memory::desc</a> b_md({K, N}, <a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dcea512dc597be7ae761876315165dc8bd2e">memory::data_type::f32</a>, {N, 1});</div><div class="line">    <a class="code" href="structdnnl_1_1memory_1_1desc.html">memory::desc</a> c_md({M, N}, <a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dcea512dc597be7ae761876315165dc8bd2e">memory::data_type::f32</a>, {N, 1});</div><div class="line"></div><div class="line">    <span class="comment">// Wrap raw pointers into oneDNN memory objects</span></div><div class="line">    <a class="code" href="structdnnl_1_1memory.html">memory</a> A_f32_m(a_md, eng, (<span class="keywordtype">void</span> *)A_f32.data());</div><div class="line">    <a class="code" href="structdnnl_1_1memory.html">memory</a> B_f32_m(b_md, eng, (<span class="keywordtype">void</span> *)B_f32.data());</div><div class="line">    <a class="code" href="structdnnl_1_1memory.html">memory</a> C_f32_m(c_md, eng, (<span class="keywordtype">void</span> *)C_f32.data());</div><div class="line"></div><div class="line">    <span class="comment">// Create a MatMul primitive</span></div><div class="line">    <a name="_a21"></a><a class="code" href="structdnnl_1_1matmul_1_1desc.html">matmul::desc</a> <a class="code" href="group__dnnl__api__primitives__common.html#gga94efdd650364f4d9776cfb9b711cbdc1a4a7fa4b07a2f5ef2534d7159225f480d">matmul_d</a>(a_md, b_md, c_md);</div><div class="line">    <a name="_a22"></a><a class="code" href="structdnnl_1_1matmul_1_1primitive__desc.html">matmul::primitive_desc</a> matmul_pd(matmul_d, eng);</div><div class="line">    <a name="_a23"></a><a class="code" href="structdnnl_1_1matmul.html">matmul</a> matmul_p(matmul_pd);</div><div class="line"></div><div class="line">    <a class="code" href="structdnnl_1_1stream.html">stream</a> s(eng);</div><div class="line">    matmul_p.execute(s,</div><div class="line">            {{<a class="code" href="group__dnnl__api__primitives__common.html#gac37ad67b48edeb9e742af0e50b70fe09">DNNL_ARG_SRC</a>, A_f32_m}, {<a name="a24"></a><a class="code" href="group__dnnl__api__primitives__common.html#gaf279f28c59a807e71a70c719db56c5b3">DNNL_ARG_WEIGHTS</a>, B_f32_m},</div><div class="line">                    {<a class="code" href="group__dnnl__api__primitives__common.html#ga3ca217e4a06d42a0ede3c018383c388f">DNNL_ARG_DST</a>, C_f32_m}});</div><div class="line">    s.wait();</div><div class="line">}</div><div class="line"></div><div class="line"><span class="comment">// Reduced precision MatMul with **dynamic** quantization</span></div><div class="line"><span class="comment">// Inputs:</span></div><div class="line"><span class="comment">// - Shape: M, N, K</span></div><div class="line"><span class="comment">// - Matrices A and B in float (would be quantized inside the function)</span></div><div class="line"><span class="comment">// Outputs:</span></div><div class="line"><span class="comment">// - Matrix C in uint8_t</span></div><div class="line"><span class="comment">// - Quantization parameters: scale_C and zp_C</span></div><div class="line"><span class="keywordtype">void</span> dynamic_q10n_matmul(int64_t M, int64_t N, int64_t K,</div><div class="line">        <span class="keyword">const</span> std::vector&lt;float&gt; &amp;A_f32, <span class="keyword">const</span> std::vector&lt;float&gt; &amp;B_f32,</div><div class="line">        std::vector&lt;uint8_t&gt; &amp;C_u8, <span class="keywordtype">float</span> &amp;scale_C, int32_t &amp;zp_C) {</div><div class="line">    <a class="code" href="structdnnl_1_1stream.html">stream</a> s(eng);</div><div class="line"></div><div class="line">    <span class="keywordtype">float</span> scale_A, scale_B;</div><div class="line">    int32_t zp_A, zp_B;</div><div class="line"></div><div class="line">    <span class="comment">// We compute q10n parameters here, but in the real world applications for</span></div><div class="line">    <span class="comment">// inputs these parameters are transferred from the previous layers</span></div><div class="line">    compute_q10n_params&lt;uint8_t&gt;(<span class="stringliteral">&quot;A&quot;</span>, A_f32, scale_A, zp_A);</div><div class="line">    compute_q10n_params&lt;int8_t&gt;(<span class="stringliteral">&quot;B&quot;</span>, B_f32, scale_B, zp_B);</div><div class="line">    assert(zp_B == 0 &amp;&amp; <span class="stringliteral">&quot;for int8 q10n we assume zero point = 0&quot;</span>);</div><div class="line"></div><div class="line">    <span class="comment">// Quantize matrix A_u8 using reorder primitive</span></div><div class="line">    std::vector&lt;uint8_t&gt; A_u8(M * K, 0);</div><div class="line">    <a class="code" href="structdnnl_1_1memory_1_1desc.html">memory::desc</a> a_u8_md({M, K}, <a name="a25"></a><a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dcea077393852be20e37026d6281827662f2">memory::data_type::u8</a>, {K, 1});</div><div class="line">    <a class="code" href="structdnnl_1_1memory.html">memory</a> A_u8_m(a_u8_md, eng, (<span class="keywordtype">void</span> *)A_u8.data());</div><div class="line">    quantize(q10n_scheme_t::DYNAMIC, A_f32, scale_A, zp_A, A_u8_m);</div><div class="line"></div><div class="line">    <span class="comment">// Quantize matrix B_s8 using reorder primitive</span></div><div class="line">    std::vector&lt;uint8_t&gt; B_s8(K * N, 0);</div><div class="line">    <a class="code" href="structdnnl_1_1memory_1_1desc.html">memory::desc</a> b_s8_md({K, N}, <a name="a26"></a><a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dcea3e8d88fdd85d7153525e0647cdd97686">memory::data_type::s8</a>, {N, 1});</div><div class="line">    <a class="code" href="structdnnl_1_1memory.html">memory</a> B_s8_m(b_s8_md, eng, (<span class="keywordtype">void</span> *)B_s8.data());</div><div class="line">    quantize(q10n_scheme_t::DYNAMIC, B_f32, scale_B, 0, B_s8_m);</div><div class="line"></div><div class="line">    <span class="comment">// Compute C_f32. We cannot directly compute C_u8 since we don&#39;t know the</span></div><div class="line">    <span class="comment">// appropriate quantization parameters.</span></div><div class="line">    <span class="comment">//</span></div><div class="line">    <span class="comment">// Note: typically the computed data type in this case is int32_t and not</span></div><div class="line">    <span class="comment">//       float. But for brevity we are going to embed the scale_A and</span></div><div class="line">    <span class="comment">//       scale_B directly in this quantized MatMul, and hence will get the</span></div><div class="line">    <span class="comment">//       intermediate computation in floating point anyways, so there is</span></div><div class="line">    <span class="comment">//       no sense to convert the result to int32_t.</span></div><div class="line">    <span class="comment">//       In theory, we could postpone using the scale_A and scale_B, compute</span></div><div class="line">    <span class="comment">//       the exact C_s32 := (A_u8 - zp_A) * B_s8, and then find the</span></div><div class="line">    <span class="comment">//       appropriate quantization parameters for matrix C.</span></div><div class="line">    <span class="comment">//       Let it be an exercise :)</span></div><div class="line"></div><div class="line">    std::vector&lt;float&gt; C_f32(M * N, 0);</div><div class="line">    <a class="code" href="structdnnl_1_1memory_1_1desc.html">memory::desc</a> c_f32_md({M, N}, <a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dcea512dc597be7ae761876315165dc8bd2e">memory::data_type::f32</a>, {N, 1});</div><div class="line">    <a class="code" href="structdnnl_1_1memory.html">memory</a> C_f32_m(c_f32_md, eng, (<span class="keywordtype">void</span> *)C_f32.data());</div><div class="line"></div><div class="line">    <span class="comment">// Create and compute a reduced precision MatMul primitive</span></div><div class="line">    {</div><div class="line">        <a class="code" href="structdnnl_1_1primitive__attr.html">primitive_attr</a> matmul_attr;</div><div class="line">        matmul_attr.<a class="code" href="structdnnl_1_1primitive__attr.html#a4b81acc8e48886313154f75c1708ae02">set_output_scales</a>(<span class="comment">/* mask */</span> 0, {<a class="code" href="group__dnnl__api__memory.html#gab16365c11b4dc88fbb453edb51f1979f">DNNL_RUNTIME_F32_VAL</a>});</div><div class="line">        matmul_attr.<a name="a27"></a><a class="code" href="structdnnl_1_1primitive__attr.html#aee82deb014cf9702ceb3e725156c25a1">set_zero_points</a>(</div><div class="line">                <a class="code" href="group__dnnl__api__primitives__common.html#gac37ad67b48edeb9e742af0e50b70fe09">DNNL_ARG_SRC</a>, <span class="comment">/* mask */</span> 0, {<a class="code" href="group__dnnl__api__memory.html#ga30139d5110e9e895ccd93fe503ca4c35">DNNL_RUNTIME_S32_VAL</a>});</div><div class="line"></div><div class="line">        <a class="code" href="structdnnl_1_1matmul_1_1desc.html">matmul::desc</a> <a class="code" href="group__dnnl__api__primitives__common.html#gga94efdd650364f4d9776cfb9b711cbdc1a4a7fa4b07a2f5ef2534d7159225f480d">matmul_d</a>(a_u8_md, b_s8_md, c_f32_md);</div><div class="line">        <a class="code" href="structdnnl_1_1matmul_1_1primitive__desc.html">matmul::primitive_desc</a> matmul_pd(matmul_d, matmul_attr, eng);</div><div class="line">        <a class="code" href="structdnnl_1_1matmul.html">matmul</a> matmul_p(matmul_pd);</div><div class="line"></div><div class="line">        <span class="comment">// Pretend the values come at run-time</span></div><div class="line">        <span class="keywordtype">float</span> output_scale = scale_A * scale_B;</div><div class="line"></div><div class="line">        <a class="code" href="structdnnl_1_1memory.html">memory</a> output_scales_m(</div><div class="line">                {{1}, <a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dcea512dc597be7ae761876315165dc8bd2e">memory::data_type::f32</a>, {1}}, eng, &amp;output_scale);</div><div class="line">        <a class="code" href="structdnnl_1_1memory.html">memory</a> zp_A_m({{1}, <a name="a28"></a><a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dceaa860868d23f3a68323a2e3f6563d7f31">memory::data_type::s32</a>, {1}}, eng, &amp;zp_A);</div><div class="line"></div><div class="line">        matmul_p.execute(s,</div><div class="line">                {{<a class="code" href="group__dnnl__api__primitives__common.html#gac37ad67b48edeb9e742af0e50b70fe09">DNNL_ARG_SRC</a>, A_u8_m}, {<a class="code" href="group__dnnl__api__primitives__common.html#gaf279f28c59a807e71a70c719db56c5b3">DNNL_ARG_WEIGHTS</a>, B_s8_m},</div><div class="line">                        {<a class="code" href="group__dnnl__api__primitives__common.html#ga3ca217e4a06d42a0ede3c018383c388f">DNNL_ARG_DST</a>, C_f32_m},</div><div class="line">                        {<a class="code" href="group__dnnl__api__primitives__common.html#ga0afb48b0c2b8f3ee30609aaa47aa29db">DNNL_ARG_ATTR_OUTPUT_SCALES</a>, output_scales_m},</div><div class="line">                        {<a class="code" href="group__dnnl__api__primitives__common.html#gaf8d879adfe2baa2f9f2a5143a0f274b6">DNNL_ARG_ATTR_ZERO_POINTS</a> | <a class="code" href="group__dnnl__api__primitives__common.html#gac37ad67b48edeb9e742af0e50b70fe09">DNNL_ARG_SRC</a>, zp_A_m}});</div><div class="line">    }</div><div class="line"></div><div class="line">    <span class="comment">// Find quantization parameters for matrix C</span></div><div class="line">    compute_q10n_params&lt;uint8_t&gt;(<span class="stringliteral">&quot;C&quot;</span>, C_f32, scale_C, zp_C);</div><div class="line"></div><div class="line">    <span class="comment">// Finally quantize the matrix C</span></div><div class="line">    <a class="code" href="structdnnl_1_1memory_1_1desc.html">memory::desc</a> c_u8_md({M, N}, <a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dcea077393852be20e37026d6281827662f2">memory::data_type::u8</a>, {N, 1});</div><div class="line">    <a class="code" href="structdnnl_1_1memory.html">memory</a> C_u8_m(c_u8_md, eng, (<span class="keywordtype">void</span> *)C_u8.data());</div><div class="line">    quantize(q10n_scheme_t::DYNAMIC, C_f32, scale_C, zp_C, C_u8_m);</div><div class="line">}</div><div class="line"></div><div class="line"><span class="comment">// Reduced precision MatMul with **static** quantization</span></div><div class="line"><span class="comment">// Inputs:</span></div><div class="line"><span class="comment">// - Shape: M, N, K</span></div><div class="line"><span class="comment">// - Matrices A and B in float (would be quantized inside the function using</span></div><div class="line"><span class="comment">//   given q10n parameters)</span></div><div class="line"><span class="comment">// - Quantization parameters for all 3 matrices:</span></div><div class="line"><span class="comment">//   - scale_A, zp_A</span></div><div class="line"><span class="comment">//   - scale_B</span></div><div class="line"><span class="comment">//   - scale_C, zp_C</span></div><div class="line"><span class="comment">// Outputs:</span></div><div class="line"><span class="comment">// - Matrix C in uint8_t</span></div><div class="line"><span class="keywordtype">void</span> static_q10n_matmul(int64_t M, int64_t N, int64_t K,</div><div class="line">        <span class="keyword">const</span> std::vector&lt;float&gt; &amp;A_f32, <span class="keyword">const</span> std::vector&lt;float&gt; &amp;B_f32,</div><div class="line">        <span class="keywordtype">float</span> scale_A, int32_t zp_A, <span class="keywordtype">float</span> scale_B, <span class="keywordtype">float</span> scale_C, int32_t zp_C,</div><div class="line">        std::vector&lt;uint8_t&gt; &amp;C_u8) {</div><div class="line">    <a class="code" href="structdnnl_1_1stream.html">stream</a> s(eng);</div><div class="line"></div><div class="line">    <span class="comment">// Quantize matrix A_u8 using reorder primitive</span></div><div class="line">    std::vector&lt;uint8_t&gt; A_u8(M * K, 0);</div><div class="line">    <a class="code" href="structdnnl_1_1memory_1_1desc.html">memory::desc</a> a_u8_md({M, K}, <a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dcea077393852be20e37026d6281827662f2">memory::data_type::u8</a>, {K, 1});</div><div class="line">    <a class="code" href="structdnnl_1_1memory.html">memory</a> A_u8_m(a_u8_md, eng, (<span class="keywordtype">void</span> *)A_u8.data());</div><div class="line">    quantize(q10n_scheme_t::STATIC, A_f32, scale_A, zp_A, A_u8_m);</div><div class="line"></div><div class="line">    <span class="comment">// Quantize matrix B_s8 using reorder primitive</span></div><div class="line">    std::vector&lt;uint8_t&gt; B_s8(K * N, 0);</div><div class="line">    <a class="code" href="structdnnl_1_1memory_1_1desc.html">memory::desc</a> b_s8_md({K, N}, <a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dcea3e8d88fdd85d7153525e0647cdd97686">memory::data_type::s8</a>, {N, 1});</div><div class="line">    <a class="code" href="structdnnl_1_1memory.html">memory</a> B_s8_m(b_s8_md, eng, (<span class="keywordtype">void</span> *)B_s8.data());</div><div class="line">    quantize(q10n_scheme_t::STATIC, B_f32, scale_B, 0, B_s8_m);</div><div class="line"></div><div class="line">    <span class="comment">// Directly compute C_u8, since we know quantization parameters for the</span></div><div class="line">    <span class="comment">// matrix C. This is the key difference compare to **dynamic** quantization.</span></div><div class="line">    {</div><div class="line">        <a class="code" href="structdnnl_1_1memory_1_1desc.html">memory::desc</a> c_u8_md({M, N}, <a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dcea077393852be20e37026d6281827662f2">memory::data_type::u8</a>, {N, 1});</div><div class="line">        <a class="code" href="structdnnl_1_1memory.html">memory</a> C_u8_m(c_u8_md, eng, (<span class="keywordtype">void</span> *)C_u8.data());</div><div class="line"></div><div class="line">        <a class="code" href="structdnnl_1_1primitive__attr.html">primitive_attr</a> matmul_attr;</div><div class="line">        matmul_attr.<a class="code" href="structdnnl_1_1primitive__attr.html#a4b81acc8e48886313154f75c1708ae02">set_output_scales</a>(</div><div class="line">                <span class="comment">/* mask */</span> 0, {scale_A * scale_B / scale_C});</div><div class="line">        matmul_attr.set_zero_points(<a class="code" href="group__dnnl__api__primitives__common.html#gac37ad67b48edeb9e742af0e50b70fe09">DNNL_ARG_SRC</a>, <span class="comment">/* mask */</span> 0, {zp_A});</div><div class="line">        matmul_attr.set_zero_points(<a class="code" href="group__dnnl__api__primitives__common.html#ga3ca217e4a06d42a0ede3c018383c388f">DNNL_ARG_DST</a>, <span class="comment">/* mask */</span> 0, {zp_C});</div><div class="line"></div><div class="line">        <a class="code" href="structdnnl_1_1matmul_1_1desc.html">matmul::desc</a> <a class="code" href="group__dnnl__api__primitives__common.html#gga94efdd650364f4d9776cfb9b711cbdc1a4a7fa4b07a2f5ef2534d7159225f480d">matmul_d</a>(a_u8_md, b_s8_md, c_u8_md);</div><div class="line">        <a class="code" href="structdnnl_1_1matmul_1_1primitive__desc.html">matmul::primitive_desc</a> matmul_pd(matmul_d, matmul_attr, eng);</div><div class="line">        <a class="code" href="structdnnl_1_1matmul.html">matmul</a> matmul_p(matmul_pd);</div><div class="line"></div><div class="line">        matmul_p.execute(s,</div><div class="line">                {{<a class="code" href="group__dnnl__api__primitives__common.html#gac37ad67b48edeb9e742af0e50b70fe09">DNNL_ARG_SRC</a>, A_u8_m}, {<a class="code" href="group__dnnl__api__primitives__common.html#gaf279f28c59a807e71a70c719db56c5b3">DNNL_ARG_WEIGHTS</a>, B_s8_m},</div><div class="line">                        {<a class="code" href="group__dnnl__api__primitives__common.html#ga3ca217e4a06d42a0ede3c018383c388f">DNNL_ARG_DST</a>, C_u8_m}});</div><div class="line">    }</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keywordtype">void</span> compare_f32_and_quantized_matmuls() {</div><div class="line">    <span class="comment">// MatMul parameters</span></div><div class="line">    <span class="keyword">const</span> int64_t M = 10, N = 20, K = 30;</div><div class="line"></div><div class="line">    <span class="comment">// Data distribution for matrices A and B</span></div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">float</span> param_A_min_val = -2.f;</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">float</span> param_A_max_val = 1.4f;</div><div class="line"></div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">float</span> param_B_min_val = -1.f;</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">float</span> param_B_max_val = -param_B_min_val; <span class="comment">// B is centered around 0</span></div><div class="line"></div><div class="line">    <span class="comment">// Thresholds</span></div><div class="line">    <span class="comment">//</span></div><div class="line">    <span class="comment">// Ideally the threshold for static quantization should be a little higher</span></div><div class="line">    <span class="comment">// than for dynamic quantization. However, we will slightly cheat on the</span></div><div class="line">    <span class="comment">// guessed q10n parameters of matrix C (see below), so we will get pretty</span></div><div class="line">    <span class="comment">// good accuracy as well.</span></div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">float</span> threshold_dynamic_q10n = 3 * 1e-2f;</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">float</span> threshold_static_q10n = 4 * 1e-2f;</div><div class="line"></div><div class="line">    <span class="comment">// Prepare matrices</span></div><div class="line">    std::vector&lt;float&gt; A_f32(M * K), B_f32(K * N), C_f32(M * N, 0);</div><div class="line">    init_vector(A_f32, param_A_min_val, param_A_max_val);</div><div class="line">    init_vector(B_f32, param_B_min_val, param_B_max_val);</div><div class="line"></div><div class="line">    <span class="comment">// Compute _true_ f32 result</span></div><div class="line">    f32_matmul_compute(M, N, K, A_f32, B_f32, C_f32);</div><div class="line"></div><div class="line">    <span class="comment">// Compute quantized variant (dynamic)</span></div><div class="line">    {</div><div class="line">        printf(<span class="stringliteral">&quot;# DYNAMIC quantization\n\n&quot;</span>);</div><div class="line"></div><div class="line">        std::vector&lt;uint8_t&gt; C_u8_dynamic_q10n(M * N, 0);</div><div class="line"></div><div class="line">        <span class="keywordtype">float</span> scale_C_dynamic_q10n; <span class="comment">// Q10n parameters we don&#39;t know yet</span></div><div class="line">        <span class="keywordtype">int</span> zp_C_dynamic_q10n;</div><div class="line"></div><div class="line">        dynamic_q10n_matmul(M, N, K, A_f32, B_f32, C_u8_dynamic_q10n,</div><div class="line">                scale_C_dynamic_q10n, zp_C_dynamic_q10n);</div><div class="line"></div><div class="line">        <span class="comment">// Compare _true_ f32 result with dynamic q10n</span></div><div class="line">        <span class="keywordtype">int</span> rc = compare_vectors(C_f32, C_u8_dynamic_q10n, scale_C_dynamic_q10n,</div><div class="line">                zp_C_dynamic_q10n, threshold_dynamic_q10n);</div><div class="line">        <span class="keywordflow">if</span> (rc) <span class="keywordflow">throw</span> std::logic_error(<span class="stringliteral">&quot;Dynamic quantization accuracy failed.&quot;</span>);</div><div class="line">    }</div><div class="line"></div><div class="line">    <span class="comment">// Compute quantized variant (static)</span></div><div class="line">    {</div><div class="line">        printf(<span class="stringliteral">&quot;# STATIC quantization\n\n&quot;</span>);</div><div class="line"></div><div class="line">        std::vector&lt;uint8_t&gt; C_u8_static_q10n(M * N, 0);</div><div class="line"></div><div class="line">        <span class="comment">// Let&#39;s pretend we know the appropriate q10n parameters (by gathering</span></div><div class="line">        <span class="comment">// some statistic or whatnot). For matrix C we will slightly _cheat_</span></div><div class="line">        <span class="comment">// and get the appropriate q10n from the actual C_f32 result that we</span></div><div class="line">        <span class="comment">// computed earlier. Of course, it is not what one would do in the</span></div><div class="line">        <span class="comment">// **static** q10n scheme (just by the definition of the **static**</span></div><div class="line">        <span class="comment">// q10n), but solely for the purpose of this example print &quot;passed&quot; in</span></div><div class="line">        <span class="comment">// the end :)</span></div><div class="line">        <span class="keyword">const</span> <span class="keywordtype">float</span> scale_A_static_q10n</div><div class="line">                = (param_A_max_val - param_A_min_val) / 128;</div><div class="line">        <span class="keyword">const</span> <span class="keywordtype">int</span> zp_A_static_q10n</div><div class="line">                = (int)(128 - param_A_max_val / scale_A_static_q10n);</div><div class="line">        <span class="keyword">const</span> <span class="keywordtype">float</span> scale_B_static_q10n</div><div class="line">                = (param_B_max_val - param_B_min_val) / 256;</div><div class="line"></div><div class="line">        <span class="keywordtype">float</span> scale_C_static_q10n;</div><div class="line">        <span class="keywordtype">int</span> zp_C_static_q10n;</div><div class="line">        <span class="comment">// !!! CHEATING STARTS HERE</span></div><div class="line">        <span class="keyword">const</span> <span class="keywordtype">char</span> *warn_message</div><div class="line">                = <span class="stringliteral">&quot;C&quot;</span></div><div class="line">                  <span class="stringliteral">&quot;\n\t*******************************************************&quot;</span></div><div class="line">                  <span class="stringliteral">&quot;\n\t* NOTE: These computation do not happen in real world *&quot;</span></div><div class="line">                  <span class="stringliteral">&quot;\n\t*       applications and used here solely to simplify *&quot;</span></div><div class="line">                  <span class="stringliteral">&quot;\n\t*       the example.                                  *&quot;</span></div><div class="line">                  <span class="stringliteral">&quot;\n\t*       Please refer to the example source code for   *&quot;</span></div><div class="line">                  <span class="stringliteral">&quot;\n\t*       more information.                             *&quot;</span></div><div class="line">                  <span class="stringliteral">&quot;\n\t*******************************************************&quot;</span>;</div><div class="line"></div><div class="line">        compute_q10n_params&lt;uint8_t&gt;(</div><div class="line">                warn_message, C_f32, scale_C_static_q10n, zp_C_static_q10n);</div><div class="line">        <span class="comment">// !!! CHEATING ENDS HERE</span></div><div class="line"></div><div class="line">        static_q10n_matmul(M, N, K, A_f32, B_f32, scale_A_static_q10n,</div><div class="line">                zp_A_static_q10n, scale_B_static_q10n, scale_C_static_q10n,</div><div class="line">                zp_C_static_q10n, C_u8_static_q10n);</div><div class="line"></div><div class="line">        <span class="comment">// Compare _true_ f32 result with static q10n</span></div><div class="line">        <span class="keywordtype">int</span> rc = compare_vectors(C_f32, C_u8_static_q10n, scale_C_static_q10n,</div><div class="line">                zp_C_static_q10n, threshold_static_q10n);</div><div class="line">        <span class="keywordflow">if</span> (rc) <span class="keywordflow">throw</span> std::logic_error(<span class="stringliteral">&quot;Static quantization accuracy failed.&quot;</span>);</div><div class="line">    }</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keywordtype">int</span> main(<span class="keywordtype">int</span> argc, <span class="keywordtype">char</span> **argv) {</div><div class="line">    <span class="keywordflow">return</span> handle_example_errors(</div><div class="line">            {<a class="code" href="structdnnl_1_1engine.html#a2635da16314dcbdb9bd9ea431316bb1aad9747e2da342bdb995f6389533ad1a3d">engine::kind::cpu</a>}, compare_f32_and_quantized_matmuls);</div><div class="line">}</div></div><!-- fragment --> </div><!-- contents -->
</div><!-- doc-content -->
<div class="footer">
    <script>
        $('#top').prependTo($('#side-nav'));
    </script>
    <div class="footer-wrapper">
        <hr>
        <ul class="footer-links">
            <li><a href="legal_information.html">Legal information</a></li>
        </ul>
    </div>
</div>