<!-- HTML header for doxygen 1.8.5-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<title>oneDNN: Primitive Attributes: Post-ops</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script src="assets/mathjax/MathJax.js?config=TeX-AMS_CHTML,dnnl"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Montserrat" rel="stylesheet">
<link href="assets/customdoxygen.css" rel="stylesheet" type="text/css" />
<script type="text/javascript" src="assets/dnn.js"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
   <div id="projectname">oneAPI Deep Neural Network Library (oneDNN)
   &#160;<span id="projectnumber">1.4.0</span>
   </div>
   <div id="projectbrief">Performance library for Deep Learning</div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Primitive Attributes: Post-ops </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>oneDNN implements some basic capabilities of operation fusion using the <b>post-ops attributes</b> API. The operation fusion typically reduces the memory bandwidth pressure hence leading to higher performance.</p>
<p>The post-ops change the default behavior of a primitive and hence are implemented through the <a class="el" href="dev_guide_attributes.html">Primitive Attributes</a> mechanism.</p>
<p>Currently the following post-ops are supported by the library:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadLeft">Post-ops \ Primitive  </th><th class="markdownTableHeadLeft"><a class="el" href="dev_guide_convolution.html">Convolution</a>  </th><th class="markdownTableHeadLeft"><a class="el" href="dev_guide_inner_product.html">Inner Product</a>  </th><th class="markdownTableHeadLeft"></th></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyLeft"><a class="el" href="dev_guide_attributes_post_ops.html#dev_guide_attributes_post_ops_eltwise">Eltwise</a>  </td><td class="markdownTableBodyLeft">Partial  </td><td class="markdownTableBodyLeft">Partial  </td><td class="markdownTableBodyLeft">Partial   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyLeft"><a class="el" href="dev_guide_attributes_post_ops.html#dev_guide_attributes_post_ops_sum">Sum</a>  </td><td class="markdownTableBodyLeft">Partial  </td><td class="markdownTableBodyLeft">N/A  </td><td class="markdownTableBodyLeft">N/A   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyLeft"><a class="el" href="dev_guide_attributes_post_ops.html#dev_guide_attributes_post_ops_depthwise">Depthwise</a>  </td><td class="markdownTableBodyLeft">Partial  </td><td class="markdownTableBodyLeft">N/A  </td><td class="markdownTableBodyLeft">N/A   </td></tr>
</table>
<p>Just like <a class="el" href="dev_guide_attributes.html">Primitive Attributes</a>, the post-ops are represented by an opaque structure (<a class="el" href="group__dnnl__api__attributes.html#ga7d715ce1a81606584df9dcf045976401">dnnl_post_ops_t</a> in C API and <a class="el" href="structdnnl_1_1post__ops.html">dnnl::post_ops</a> in C++ API) which is copied once it is attached to the attributes using C++ <a class="el" href="structdnnl_1_1primitive__attr.html#ac830fa9f4fcf480b494d73153ad579bf">dnnl::primitive_attr::set_post_ops</a> or C <a class="el" href="group__dnnl__api__attributes.html#ga7045d42606599f156bfca69820c21ea2">dnnl_primitive_attr_set_post_ops</a> functions. These attributes then are passed to a primitive descriptor creation function to take effect. Below is a simple skeleton for C++ API:</p>
<div class="fragment"><div class="line"><a class="code" href="structdnnl_1_1post__ops.html">dnnl::post_ops</a> po; <span class="comment">// default empty post-ops</span></div><div class="line">assert(po.<a class="code" href="structdnnl_1_1post__ops.html#a84653b68d83c2d84d3ac432a8dc1f5fd">len</a>() == 0); <span class="comment">// no post-ops attached</span></div><div class="line"></div><div class="line">po.append_SOMETHING(params); <span class="comment">// append some particular post-op</span></div><div class="line">po.append_SOMETHING_ELSE(other_params); <span class="comment">// append one more post-op</span></div><div class="line"></div><div class="line"><span class="comment">// (!) Note that the order of appending matters!</span></div><div class="line">assert(po.<a class="code" href="structdnnl_1_1post__ops.html#a84653b68d83c2d84d3ac432a8dc1f5fd">len</a>() == 2);</div><div class="line"></div><div class="line"><a class="code" href="structdnnl_1_1primitive__attr.html">dnnl::primitive_attr</a> attr; <span class="comment">// default attributes</span></div><div class="line">attr.<a class="code" href="structdnnl_1_1primitive__attr.html#ac830fa9f4fcf480b494d73153ad579bf">set_post_ops</a>(po); <span class="comment">// attach the post-ops to the attr</span></div><div class="line"></div><div class="line"><span class="comment">// further po changes would not affect attr</span></div><div class="line"></div><div class="line">primitive::primitive_desc op_pd(params, attr); <span class="comment">// create a pd with the attr</span></div></div><!-- fragment --><dl class="section note"><dt>Note</dt><dd>Different post-ops can be chained together by appending one after another. Note that the appending order matters: the sequence of the post-ops is executed in the order of appearance.</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>Different primitives have different capabilities on supporting post-ops. Moreover, the support might also depend on the actual implementation of a primitive. For instance, the library generally doesn't support post-ops for reference primitives (which are typically very slow, so there is no point in doing the actual fusion). So the robust integration should handle errors accordingly. See the <a class="el" href="dev_guide_attributes.html#dev_guide_attributes_error_handling">section on attributes error handling</a>.</dd></dl>
<p>The post-op object can be inspected by <a class="el" href="structdnnl_1_1post__ops.html#a454acad1a18f2763f07b42912778c0f8">dnnl::post_ops::kind()</a> function that takes an index of the post-op (that must be less than the value returned by <a class="el" href="structdnnl_1_1post__ops.html#a84653b68d83c2d84d3ac432a8dc1f5fd">dnnl::post_ops::len()</a>) and returns it's kind.</p>
<h2>Supported Post-ops</h2>
<p><a class="anchor" id="dev_guide_attributes_post_ops_eltwise"></a></p><h3>Eltwise Post-op</h3>
<p>The eltwise post-op enables fusing a primitive with a <a class="el" href="dev_guide_eltwise.html">Eltwise</a> primitive. This is probably one of the most popular kinds of fusion: an eltwise (typically an activation function) with preceding convolution or inner product.</p>
<p>The <a class="el" href="structdnnl_1_1primitive.html#ad1ec93215a0cf3aa0a32bae0c2cd9169">dnnl::primitive::kind</a> of this post-op is <a class="el" href="structdnnl_1_1primitive.html#ad1ec93215a0cf3aa0a32bae0c2cd9169a98b908c7d0339bb6a4832db44fc2c8da" title="An element-wise primitive. ">dnnl::primitive::kind::eltwise</a>.</p>
<p>API:</p><ul>
<li>C: <a class="el" href="group__dnnl__api__attributes.html#gad3a93e3c396b07066d42eadbe119b7a4">dnnl_post_ops_append_eltwise</a></li>
<li>C++: <a class="el" href="structdnnl_1_1post__ops.html#a66606f08467b19091e696b52a2f789e6">dnnl::post_ops::append_eltwise</a></li>
</ul>
<p>The parameters (C++ API for simplicity): </p><div class="fragment"><div class="line"><span class="keywordtype">void</span> <a class="code" href="structdnnl_1_1post__ops.html#a66606f08467b19091e696b52a2f789e6">dnnl::post_ops::append_eltwise</a>(</div><div class="line">        <span class="keywordtype">float</span> scale, <span class="comment">// scaling factor (described below)</span></div><div class="line">        <a class="code" href="group__dnnl__api__attributes.html#ga00377dd4982333e42e8ae1d09a309640">algorithm</a> alg, <span class="keywordtype">float</span> alpha, <span class="keywordtype">float</span> beta <span class="comment">// same as in Eltwise primitive</span></div><div class="line">        );</div></div><!-- fragment --><p>The <code>alg</code>, <code>alpha</code>, and <code>beta</code> parameters are the same as in <a class="el" href="dev_guide_eltwise.html">Eltwise</a>.</p>
<p>The Eltwise post-op replaces: </p><p class="formulaDsp">
\[ \dst(:) = \operatorname{Op}(...) \]
</p>
<p>with</p>
<p class="formulaDsp">
\[ \dst(:) = scale \cdot \operatorname{Eltwise}( \operatorname{Op}(...) ) \]
</p>
<p>The intermediate result of \(\operatorname{Op}(...)\) is not stored. Hence in most of the case this kind of fusion cannot be used with the training.</p>
<p>The \(scale\) factor is supported in <a class="el" href="dev_guide_attributes_quantization.html">INT8</a> inference only. For other cases the scale must be equal to <code>1.0</code>.</p>
<p><a class="anchor" id="dev_guide_attributes_post_ops_sum"></a></p><h3>Sum Post-op</h3>
<p>Appends an accumulation (sum) post-op. Prior to accumulating the result, the previous value would be multiplied by scale.</p>
<p>The kind of this post-op is <a class="el" href="structdnnl_1_1primitive.html#ad1ec93215a0cf3aa0a32bae0c2cd9169a1d623b89683f9ce4e074de1676d12416" title="A summation primitive. ">dnnl::primitive::kind::sum</a>.</p>
<p>This feature might improve performance for cases like residual learning blocks, where the result of a convolution is accumulated to the previously computed activations. The scale parameter can be used in <a class="el" href="dev_guide_attributes_quantization.html">INT8</a> inference only when the result and previous activations have different logical scaling factors.</p>
<p>The sum post-op replaces </p><p class="formulaDsp">
\[ \dst(:) = \operatorname{Op}(...) \]
</p>
<p>with</p>
<p class="formulaDsp">
\[ \dst(:) = scale \cdot \dst(:) + \operatorname{Op}(...) \]
</p>
<dl class="section warning"><dt>Warning</dt><dd>This post-op (as well as all the others) disregards the original layout of the destination; that is, the layout of the original destination is expected to be the same as the layout of the output destination.</dd></dl>
<p><a class="anchor" id="dev_guide_attributes_post_ops_depthwise"></a></p><h3>Depthwise Post-op</h3>
<p>Appends a Depthwise convolution as a post-op. This post-op can only be fused with 1x1 convolution as generally seen in models (like MobileNet_v1) that use a stack of Separable convolutions: Depthwise convolution followed by 1x1 convolution. The stack of these Separable convolutions (like in MobileNet_v1) provide an opportunity to fuse 1x1-Convolution with bandwidth-limited Depthwise convolution.</p>
<p>The <a class="el" href="structdnnl_1_1primitive.html#ad1ec93215a0cf3aa0a32bae0c2cd9169">dnnl::primitive::kind</a> of this post-op is <a class="el" href="structdnnl_1_1primitive.html#ad1ec93215a0cf3aa0a32bae0c2cd9169aa9595c1c24c33b16056d2ad07e71682d" title="A convolution primitive. ">dnnl::primitive::kind::convolution</a>.</p>
<p>There are two variants of this post-op: dw_k3s1p1 and dw_k3_s2p1 for stride-1 and and stride-2 respectively.</p>
<p>API:</p><ul>
<li>C: <a class="el" href="group__dnnl__api__attributes.html#ga60126f67fa1dd9df8cca16e2dd471184">dnnl_post_ops_append_dw_k3s1p1</a> , <a class="el" href="group__dnnl__api__attributes.html#gaa31670d933930b7c7940379bff0de326">dnnl_post_ops_append_dw_k3s2p1</a></li>
<li>C++: <a class="el" href="structdnnl_1_1post__ops.html#a4229db0e1e1eab273ed0e2b3e18402de">dnnl::post_ops::append_dw_k3s1p1</a> , <a class="el" href="structdnnl_1_1post__ops.html#a88ed886c27b4df4667431ed48d29f4c1">dnnl::post_ops::append_dw_k3s2p1</a></li>
</ul>
<p>For better readability, below we assume a 2D convolution and use the following notations:</p>
<p><code>conv_1x1</code> Convolution with weights spatial=1 i.e., <code>kh</code> = <code>kw</code> = 1.</p>
<p><code>conv_dw</code> Depthwise convolution with weights spatial=3 i.e., <code>kh</code> = <code>kw</code> = 3, <code>g</code> = <code>oc</code> = <code>ic</code> and <code>pad_l</code> = <code>pad_r</code> = {1, 1}.</p>
<p>The Depthwise post-op replaces</p>
<p class="formulaDsp">
\[ dst(:) = Conv_{1x1}(...) \]
</p>
<p>with</p>
<p class="formulaDsp">
\[ dst(:) = Conv_{dw}(Conv_{1x1}(...)) \]
</p>
<p>The final output dimensions of the after post-op is defined as</p>
<p class="formulaDsp">
\[ dst_{conv_dw} = \{ n, oc_{1x1}, \operatorname{ceil}(oh_{conv_{1x1}}/stride), \operatorname{ceil}(ow_{conv_{1x1}}/stride) \} \]
</p>
<p>where <code>oh_conv_1x1</code>, <code>ow_conv_1x1</code> are height and width of conv_1x1 destination.</p>
<div class="image">
<img src="img_depthwise_fusion.jpg" alt="img_depthwise_fusion.jpg"/>
<div class="caption">
Fusion</div></div>
<p> Supported data types</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadLeft">conv 1x1 output data type  </th><th class="markdownTableHeadLeft">depthwise post-op output data type  </th><th class="markdownTableHeadLeft">depthwise post-op weights data type  </th><th class="markdownTableHeadLeft">dep   </th></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">u8, s8  </td><td class="markdownTableBodyLeft">u8, s8, s32, f32  </td><td class="markdownTableBodyLeft">s8  </td><td class="markdownTableBodyLeft">f32, s32   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyLeft">f32  </td><td class="markdownTableBodyLeft">f32  </td><td class="markdownTableBodyLeft">f32  </td><td class="markdownTableBodyLeft">f32   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">bf16  </td><td class="markdownTableBodyLeft">bf16, f32  </td><td class="markdownTableBodyLeft">bf16  </td><td class="markdownTableBodyLeft">f32, bf16   </td></tr>
</table>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>Currently only supported for 2D 1x1 convolution.</li>
<li>Only eltwise post-op can be part of post-op chain (i.e., sum post-op is not supported)</li>
<li>The <code>dst_1x1</code>, <code>wei_dw</code> and <code>dst_dw</code> are assumed to be <a class="el" href="group__dnnl__api__memory.html#gga395e42b594683adb25ed2d842bb3091dafee39ac6fff0325cae43cd66495c18ac" title="Undefined memory format tag. ">dnnl_format_tag_any</a>.</li>
</ul>
</dd></dl>
<h2>Examples of Chained Post-ops</h2>
<p>Different post-ops can be chained together by appending one after another. Note that the order matters: the post-ops are executed in the order they have been appended.</p>
<p>Let's consider some examples.</p>
<h3>Sum -&gt; ReLU</h3>
<p>This pattern is pretty common for the CNN topologies from the ResNet family.</p>
<div class="fragment"><div class="line"><a class="code" href="structdnnl_1_1post__ops.html">dnnl::post_ops</a> po;</div><div class="line">po.<a class="code" href="structdnnl_1_1post__ops.html#a078ab8ec15423d2b3d26f3619a78ca38">append_sum</a>(</div><div class="line">        <span class="comment">/* scale = */</span> 1.f);</div><div class="line">po.<a class="code" href="structdnnl_1_1post__ops.html#a66606f08467b19091e696b52a2f789e6">append_eltwise</a>(</div><div class="line">        <span class="comment">/* scale     = */</span> 1.f,</div><div class="line">        <span class="comment">/* alg kind  = */</span> <a class="code" href="group__dnnl__api__attributes.html#gga00377dd4982333e42e8ae1d09a309640aba09bebb742494255b90b43871c01c69">dnnl::algorithm::eltwise_relu</a>,</div><div class="line">        <span class="comment">/* neg slope = */</span> 0.f,</div><div class="line">        <span class="comment">/* unused for relu */</span> 0.f);</div><div class="line"></div><div class="line"><a class="code" href="structdnnl_1_1primitive__attr.html">dnnl::primitive_attr</a> attr;</div><div class="line">attr.<a class="code" href="structdnnl_1_1primitive__attr.html#ac830fa9f4fcf480b494d73153ad579bf">set_post_ops</a>(po);</div><div class="line"></div><div class="line">convolution_forward::primitive_desc(conv_d, attr, engine);</div></div><!-- fragment --><p>This will lead to the following primitive behavior:</p>
<p class="formulaDsp">
\[ \dst(:) = \operatorname{ReLU}(\dst(:) + \operatorname{conv}(\src(:), \weights(:)) \]
</p>
<p><a class="anchor" id="dev_guide_attributes_post_ops_with_scales"></a></p><h3>Tanh -&gt; Sum -&gt; ScaleShift</h3>
<p>The hypothetical example to illustrate the sequence of operations applied. We also set all the scales to non-one to as well as use <a class="el" href="structdnnl_1_1primitive__attr.html#a4b81acc8e48886313154f75c1708ae02">dnnl::primitive_attr::set_output_scales</a> which will be covered in <a class="el" href="dev_guide_attributes_quantization.html">Primitive Attributes: Quantization</a>. Unfortunately (or fortunately) the sequence is not supported by the library and is merely used to illustrate the semantics of post-ops.</p>
<div class="fragment"><div class="line"><a class="code" href="structdnnl_1_1post__ops.html">dnnl::post_ops</a> po;</div><div class="line">po.<a class="code" href="structdnnl_1_1post__ops.html#a66606f08467b19091e696b52a2f789e6">append_eltwise</a>(</div><div class="line">        <span class="comment">/* scale     = */</span> s_tanh,</div><div class="line">        <span class="comment">/* alg kind  = */</span> <a class="code" href="group__dnnl__api__attributes.html#gga00377dd4982333e42e8ae1d09a309640a38dd7159307eab45742c78e72f06abb0">dnnl::algorithm::eltwise_tanh</a>,</div><div class="line">        <span class="comment">/* unused for tanh */</span> 0.f,</div><div class="line">        <span class="comment">/* unused for tanh */</span> 0.f);</div><div class="line">po.<a class="code" href="structdnnl_1_1post__ops.html#a078ab8ec15423d2b3d26f3619a78ca38">append_sum</a>(</div><div class="line">        <span class="comment">/* scale     = */</span> s_sum);</div><div class="line">po.<a class="code" href="structdnnl_1_1post__ops.html#a66606f08467b19091e696b52a2f789e6">append_eltwise</a>(</div><div class="line">        <span class="comment">/* scale     = */</span> s_linear,</div><div class="line">        <span class="comment">/* alg kind  = */</span> <a class="code" href="group__dnnl__api__attributes.html#gga00377dd4982333e42e8ae1d09a309640a21aba6844d2de47b92ab1d110f561945">dnnl::algorithm::eltwise_linear</a>,</div><div class="line">        <span class="comment">/* scale     = */</span> alpha,</div><div class="line">        <span class="comment">/* shift     = */</span> beta);</div><div class="line"></div><div class="line"><a class="code" href="structdnnl_1_1primitive__attr.html">dnnl::primitive_attr</a> attr;</div><div class="line">attr.<a class="code" href="structdnnl_1_1primitive__attr.html#a4b81acc8e48886313154f75c1708ae02">set_output_scales</a>(0, {s_conv});</div><div class="line">attr.<a class="code" href="structdnnl_1_1primitive__attr.html#ac830fa9f4fcf480b494d73153ad579bf">set_post_ops</a>(po);</div><div class="line"></div><div class="line">convolution_forward::primitive_desc(conv_d, attr, engine);</div></div><!-- fragment --><p>This will lead to the following primitive behavior (for better readability the tensors are designated by their names only; i.e., <code>(:)</code> is omitted):</p>
<p class="formulaDsp">
\[ \dst = s_{linear} \cdot ( \alpha \cdot ( s_{sum} \cdot \dst + s_{tanh} \cdot \tanh ( s_{conv} \cdot \operatorname{conv}(\src, \weights) ) ) + \beta ) \]
</p>
<p><a class="anchor" id="dev_guide_attributes_post_ops_depthwise_fusion"></a></p><h3>Relu -&gt; Depthwise -&gt; Relu</h3>
<p>An example of fusing depthwise convolution with 1x1 convolution in MobileNet.</p>
<div class="fragment"><div class="line"><a class="code" href="structdnnl_1_1post__ops.html">dnnl::post_ops</a> po;</div><div class="line"></div><div class="line">po.<a class="code" href="structdnnl_1_1post__ops.html#a66606f08467b19091e696b52a2f789e6">append_eltwise</a>(</div><div class="line">        <span class="comment">/* scale     = */</span> 1.f,</div><div class="line">        <span class="comment">/* alg kind  = */</span> <a class="code" href="group__dnnl__api__attributes.html#gga00377dd4982333e42e8ae1d09a309640aba09bebb742494255b90b43871c01c69">dnnl::algorithm::eltwise_relu</a>,</div><div class="line">        <span class="comment">/* neg slope = */</span> 0.f,</div><div class="line">        <span class="comment">/* unused for relu */</span> 0.f);</div><div class="line"></div><div class="line">po.<a class="code" href="structdnnl_1_1post__ops.html#a4229db0e1e1eab273ed0e2b3e18402de">append_dw_k3s1p1</a>( <span class="comment">/* or po.append_dw_k3s2p1 for depthwise with stride=2*/</span></div><div class="line">        <span class="comment">/* depthwise weights data type = */</span> <a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dcea3e8d88fdd85d7153525e0647cdd97686">dnnl::memory::data_type::s8</a>,</div><div class="line">        <span class="comment">/* depthwise bias data type (undef implies no bias) = */</span> <a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dceaf31ee5e3824f1f5e5d206bdf3029f22b">dnnl::memory::data_type::undef</a>,</div><div class="line">        <span class="comment">/* depthwise destination data type = */</span> <a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dcea077393852be20e37026d6281827662f2">dnnl::memory::data_type::u8</a>,</div><div class="line">        <span class="comment">/* mask for output scales of depthwise output = */</span> mask,</div><div class="line">        <span class="comment">/* output scales for depthwise output = */</span> scales_depthwise)</div><div class="line"></div><div class="line">po.<a class="code" href="structdnnl_1_1post__ops.html#a66606f08467b19091e696b52a2f789e6">append_eltwise</a>(</div><div class="line">        <span class="comment">/* scale     = */</span> 1.f,</div><div class="line">        <span class="comment">/* alg kind  = */</span> <a class="code" href="group__dnnl__api__attributes.html#gga00377dd4982333e42e8ae1d09a309640aba09bebb742494255b90b43871c01c69">dnnl::algorithm::eltwise_relu</a>,</div><div class="line">        <span class="comment">/* neg slope = */</span> 0.f,</div><div class="line">        <span class="comment">/* unused for relu */</span> 0.f);</div><div class="line"></div><div class="line"><a class="code" href="structdnnl_1_1primitive__attr.html">dnnl::primitive_attr</a> attr;</div><div class="line">attr.<a class="code" href="structdnnl_1_1primitive__attr.html#a4b81acc8e48886313154f75c1708ae02">set_output_scales</a>(0, {output_scales_1x1_conv});</div><div class="line">attr.<a class="code" href="structdnnl_1_1primitive__attr.html#ac830fa9f4fcf480b494d73153ad579bf">set_post_ops</a>(po);</div><div class="line"></div><div class="line"><span class="keyword">auto</span> cpd = convolution_forward::primitive_desc(conv_1x1, attr, engine);</div><div class="line"><span class="keyword">auto</span> dw_weight_md = cpd.query(query::exec_arg_md,</div><div class="line">                <a class="code" href="group__dnnl__api__primitives__common.html#ga47534804c9b2f9ede6b875f6cb08cc35">DNNL_ARG_ATTR_POST_OP_DW</a> | <a class="code" href="group__dnnl__api__primitives__common.html#gaf279f28c59a807e71a70c719db56c5b3">DNNL_ARG_WEIGHTS</a>);</div><div class="line"><span class="keyword">auto</span> dw_bias_md = cpd.query(query::exec_arg_md,</div><div class="line">                <a class="code" href="group__dnnl__api__primitives__common.html#ga47534804c9b2f9ede6b875f6cb08cc35">DNNL_ARG_ATTR_POST_OP_DW</a> | <a class="code" href="group__dnnl__api__primitives__common.html#gad0cbc09942aba93fbe3c0c2e09166f0d">DNNL_ARG_BIAS</a>);</div></div><!-- fragment --><p>This will lead to the following primitive behaviour:</p>
<p class="formulaDsp">
\[ dst = ReLU_{depthwise} ( scales_{depthwise} \cdot ( conv_{depthwise} ( ReLU_{1x1} ( scales_{conv_{1x1}} \cdot ( conv_{1x1}() ) ) ) ) ) \]
</p>
 </div></div><!-- contents -->
<div class="footer">
    <div class="footer-wrapper">
        <ul id="footer-links">
            <li><a href="legal_information.html">Legal information</a></li>
        </ul>
    </div>
</div>