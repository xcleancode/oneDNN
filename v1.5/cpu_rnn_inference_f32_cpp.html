<!-- HTML header for doxygen 1.8.5-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<title>oneDNN: RNN f32 inference example</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script src="assets/mathjax/MathJax.js?config=TeX-AMS_CHTML,dnnl"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Montserrat" rel="stylesheet">
<link href="assets/customdoxygen.css" rel="stylesheet" type="text/css" />
<script type="text/javascript" src="assets/dnn.js"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
   <div id="projectname">oneAPI Deep Neural Network Library (oneDNN)
   &#160;<span id="projectnumber">1.5.0</span>
   </div>
   <div id="projectbrief">Performance library for Deep Learning</div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">RNN f32 inference example </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>This C++ API example demonstrates how to build GNMT model inference.</p>
<blockquote class="doxtable">
<p>Example code: <a class="el" href="cpu_rnn_inference_f32_8cpp-example.html">cpu_rnn_inference_f32.cpp</a> </p>
</blockquote>
<p>For the encoder we use:</p><ul>
<li>one primitive for the bidirectional layer of the encoder</li>
<li>one primitive for all remaining unidirectional layers in the encoder For the decoder we use:</li>
<li>one primitive for the first iteration</li>
<li>one primitive for all subsequent iterations in the decoder. Note that in this example, this primitive computes the states in place.</li>
<li>the attention mechanism is implemented separately as there is no support for the context vectors in oneDNN yet</li>
</ul>
<p>Initialize a CPU engine and stream. The last parameter in the call represents the index of the engine. </p><div class="fragment"><div class="line">    <span class="keyword">auto</span> cpu_engine = <a class="code" href="group__dnnl__api__primitives__common.html#gga94efdd650364f4d9776cfb9b711cbdc1aad1943a9fd6d3d7ee1e6af41a5b0d3e7">engine</a>(engine::kind::cpu, 0);</div><div class="line">    stream s(cpu_engine);</div></div><!-- fragment --><p>Declare encoder net and decoder net </p><div class="fragment"><div class="line">    std::vector&lt;primitive&gt; encoder_net, decoder_net;</div><div class="line">    std::vector&lt;std::unordered_map&lt;int, memory&gt;&gt; encoder_net_args,</div><div class="line">            decoder_net_args;</div><div class="line"></div><div class="line">    std::vector&lt;float&gt; net_src(batch * src_seq_length_max * feature_size, 1.0f);</div><div class="line">    std::vector&lt;float&gt; net_dst(batch * tgt_seq_length_max * feature_size, 1.0f);</div></div><!-- fragment --><p><b>Encoder</b></p>
<p>Initialize Encoder Memory </p><div class="fragment"><div class="line">    memory::dims enc_bidir_src_layer_tz</div><div class="line">            = {src_seq_length_max, batch, feature_size};</div><div class="line">    memory::dims enc_bidir_weights_layer_tz</div><div class="line">            = {enc_bidir_n_layers, 2, feature_size, lstm_n_gates, feature_size};</div><div class="line">    memory::dims enc_bidir_weights_iter_tz</div><div class="line">            = {enc_bidir_n_layers, 2, feature_size, lstm_n_gates, feature_size};</div><div class="line">    memory::dims enc_bidir_bias_tz</div><div class="line">            = {enc_bidir_n_layers, 2, lstm_n_gates, feature_size};</div><div class="line">    memory::dims enc_bidir_dst_layer_tz</div><div class="line">            = {src_seq_length_max, batch, 2 * feature_size};</div></div><!-- fragment --><p>Encoder: 1 bidirectional layer and 7 unidirectional layers</p>
<p>Create the memory for user data </p><div class="fragment"><div class="line">    <span class="keyword">auto</span> user_enc_bidir_src_layer_md = <a class="code" href="structdnnl_1_1memory_1_1desc.html">dnnl::memory::desc</a>(</div><div class="line">            {enc_bidir_src_layer_tz}, <a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dcea512dc597be7ae761876315165dc8bd2e">dnnl::memory::data_type::f32</a>,</div><div class="line">            <a class="code" href="structdnnl_1_1memory.html#a8e71077ed6a5f7fb7b3e6e1a5a2ecf3fac775cf954921a129a65eb929476de911">dnnl::memory::format_tag::tnc</a>);</div><div class="line"></div><div class="line">    <span class="keyword">auto</span> user_enc_bidir_wei_layer_md = <a class="code" href="structdnnl_1_1memory_1_1desc.html">dnnl::memory::desc</a>(</div><div class="line">            {enc_bidir_weights_layer_tz}, <a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dcea512dc597be7ae761876315165dc8bd2e">dnnl::memory::data_type::f32</a>,</div><div class="line">            <a class="code" href="structdnnl_1_1memory.html#a8e71077ed6a5f7fb7b3e6e1a5a2ecf3fa4e62e330c56963f9ead98490cd57ef7b">dnnl::memory::format_tag::ldigo</a>);</div><div class="line"></div><div class="line">    <span class="keyword">auto</span> user_enc_bidir_wei_iter_md = <a class="code" href="structdnnl_1_1memory_1_1desc.html">dnnl::memory::desc</a>(</div><div class="line">            {enc_bidir_weights_iter_tz}, <a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dcea512dc597be7ae761876315165dc8bd2e">dnnl::memory::data_type::f32</a>,</div><div class="line">            <a class="code" href="structdnnl_1_1memory.html#a8e71077ed6a5f7fb7b3e6e1a5a2ecf3fa4e62e330c56963f9ead98490cd57ef7b">dnnl::memory::format_tag::ldigo</a>);</div><div class="line"></div><div class="line">    <span class="keyword">auto</span> user_enc_bidir_bias_md = <a class="code" href="structdnnl_1_1memory_1_1desc.html">dnnl::memory::desc</a>({enc_bidir_bias_tz},</div><div class="line">            <a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dcea512dc597be7ae761876315165dc8bd2e">dnnl::memory::data_type::f32</a>, <a class="code" href="structdnnl_1_1memory.html#a8e71077ed6a5f7fb7b3e6e1a5a2ecf3fab8690cd92ccee6a0ad55faccc0346aab">dnnl::memory::format_tag::ldgo</a>);</div><div class="line"></div><div class="line">    <span class="keyword">auto</span> user_enc_bidir_src_layer_memory = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(</div><div class="line">            user_enc_bidir_src_layer_md, cpu_engine, net_src.data());</div><div class="line">    <span class="keyword">auto</span> user_enc_bidir_wei_layer_memory</div><div class="line">            = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(user_enc_bidir_wei_layer_md, cpu_engine,</div><div class="line">                    user_enc_bidir_wei_layer.data());</div><div class="line">    <span class="keyword">auto</span> user_enc_bidir_wei_iter_memory</div><div class="line">            = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(user_enc_bidir_wei_iter_md, cpu_engine,</div><div class="line">                    user_enc_bidir_wei_iter.data());</div><div class="line">    <span class="keyword">auto</span> user_enc_bidir_bias_memory = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(</div><div class="line">            user_enc_bidir_bias_md, cpu_engine, user_enc_bidir_bias.data());</div><div class="line"></div></div><!-- fragment --><p>Create memory descriptors for RNN data w/o specified layout </p><div class="fragment"><div class="line">    <span class="keyword">auto</span> enc_bidir_wei_layer_md = memory::desc({enc_bidir_weights_layer_tz},</div><div class="line">            memory::data_type::f32, memory::format_tag::any);</div><div class="line"></div><div class="line">    <span class="keyword">auto</span> enc_bidir_wei_iter_md = memory::desc({enc_bidir_weights_iter_tz},</div><div class="line">            memory::data_type::f32, memory::format_tag::any);</div><div class="line"></div><div class="line">    <span class="keyword">auto</span> enc_bidir_dst_layer_md = memory::desc({enc_bidir_dst_layer_tz},</div><div class="line">            memory::data_type::f32, memory::format_tag::any);</div><div class="line"></div></div><!-- fragment --><p>Create bidirectional RNN </p><div class="fragment"><div class="line"></div><div class="line">    lstm_forward::desc bi_layer_desc(prop_kind::forward_inference,</div><div class="line">            rnn_direction::bidirectional_concat, user_enc_bidir_src_layer_md,</div><div class="line">            memory::desc(), memory::desc(), enc_bidir_wei_layer_md,</div><div class="line">            enc_bidir_wei_iter_md, user_enc_bidir_bias_md,</div><div class="line">            enc_bidir_dst_layer_md, memory::desc(), memory::desc());</div><div class="line"></div><div class="line">    <span class="keyword">auto</span> enc_bidir_prim_desc</div><div class="line">            = <a class="code" href="structdnnl_1_1lstm__forward_1_1primitive__desc.html">dnnl::lstm_forward::primitive_desc</a>(bi_layer_desc, cpu_engine);</div></div><!-- fragment --><p>Create memory for input data and use reorders to reorder user data to internal representation </p><div class="fragment"><div class="line">    <span class="keyword">auto</span> enc_bidir_wei_layer_memory</div><div class="line">            = memory(enc_bidir_prim_desc.weights_layer_desc(), cpu_engine);</div><div class="line">    <span class="keyword">auto</span> enc_bidir_wei_layer_reorder_pd = reorder::primitive_desc(</div><div class="line">            user_enc_bidir_wei_layer_memory, enc_bidir_wei_layer_memory);</div><div class="line">    reorder(enc_bidir_wei_layer_reorder_pd)</div><div class="line">            .execute(s, user_enc_bidir_wei_layer_memory,</div><div class="line">                    enc_bidir_wei_layer_memory);</div></div><!-- fragment --><p>Encoder : add the bidirectional rnn primitive with related arguments into encoder_net </p><div class="fragment"><div class="line">    encoder_net.push_back(lstm_forward(enc_bidir_prim_desc));</div><div class="line">    encoder_net_args.push_back(</div><div class="line">            {{<a class="code" href="group__dnnl__api__primitives__common.html#gab91ce4d04cf4e98e3a407daa0676764f">DNNL_ARG_SRC_LAYER</a>, user_enc_bidir_src_layer_memory},</div><div class="line">                    {<a class="code" href="group__dnnl__api__primitives__common.html#ga1ac9e1f1327be3902b488b64bae1b4c5">DNNL_ARG_WEIGHTS_LAYER</a>, enc_bidir_wei_layer_memory},</div><div class="line">                    {<a class="code" href="group__dnnl__api__primitives__common.html#ga5a9c39486c01ad263e29677a32735af8">DNNL_ARG_WEIGHTS_ITER</a>, enc_bidir_wei_iter_memory},</div><div class="line">                    {<a class="code" href="group__dnnl__api__primitives__common.html#gad0cbc09942aba93fbe3c0c2e09166f0d">DNNL_ARG_BIAS</a>, user_enc_bidir_bias_memory},</div><div class="line">                    {<a class="code" href="group__dnnl__api__primitives__common.html#gacfc123a6a4ff3b4af4cd27ed66fb8528">DNNL_ARG_DST_LAYER</a>, enc_bidir_dst_layer_memory}});</div></div><!-- fragment --><p>Encoder: unidirectional layers</p>
<p>First unidirectinal layer scales 2 * feature_size output of bidirectional layer to feature_size output </p><div class="fragment"><div class="line">    std::vector&lt;float&gt; user_enc_uni_first_wei_layer(</div><div class="line">            1 * 1 * 2 * feature_size * lstm_n_gates * feature_size, 1.0f);</div><div class="line">    std::vector&lt;float&gt; user_enc_uni_first_wei_iter(</div><div class="line">            1 * 1 * feature_size * lstm_n_gates * feature_size, 1.0f);</div><div class="line">    std::vector&lt;float&gt; user_enc_uni_first_bias(</div><div class="line">            1 * 1 * lstm_n_gates * feature_size, 1.0f);</div></div><!-- fragment --><p>Encoder : Create unidirection RNN for first cell </p><div class="fragment"><div class="line">    lstm_forward::desc enc_uni_first_layer_desc(prop_kind::forward_inference,</div><div class="line">            rnn_direction::unidirectional_left2right, enc_bidir_dst_layer_md,</div><div class="line">            memory::desc(), memory::desc(), enc_uni_first_wei_layer_md,</div><div class="line">            enc_uni_first_wei_iter_md, user_enc_uni_first_bias_md,</div><div class="line">            enc_uni_first_dst_layer_md, memory::desc(), memory::desc());</div><div class="line"></div><div class="line">    <span class="keyword">auto</span> enc_uni_first_prim_desc = <a class="code" href="structdnnl_1_1lstm__forward_1_1primitive__desc.html">dnnl::lstm_forward::primitive_desc</a>(</div><div class="line">            enc_uni_first_layer_desc, cpu_engine);</div><div class="line"></div></div><!-- fragment --><p>Encoder : add the first unidirectional rnn primitive with related arguments into encoder_net</p>
<div class="fragment"><div class="line">    <span class="comment">// TODO: add a reorder when they will be available</span></div><div class="line">    encoder_net.push_back(lstm_forward(enc_uni_first_prim_desc));</div><div class="line">    encoder_net_args.push_back(</div><div class="line">            {{<a class="code" href="group__dnnl__api__primitives__common.html#gab91ce4d04cf4e98e3a407daa0676764f">DNNL_ARG_SRC_LAYER</a>, enc_bidir_dst_layer_memory},</div><div class="line">                    {<a class="code" href="group__dnnl__api__primitives__common.html#ga1ac9e1f1327be3902b488b64bae1b4c5">DNNL_ARG_WEIGHTS_LAYER</a>, enc_uni_first_wei_layer_memory},</div><div class="line">                    {<a class="code" href="group__dnnl__api__primitives__common.html#ga5a9c39486c01ad263e29677a32735af8">DNNL_ARG_WEIGHTS_ITER</a>, enc_uni_first_wei_iter_memory},</div><div class="line">                    {<a class="code" href="group__dnnl__api__primitives__common.html#gad0cbc09942aba93fbe3c0c2e09166f0d">DNNL_ARG_BIAS</a>, user_enc_uni_first_bias_memory},</div><div class="line">                    {<a class="code" href="group__dnnl__api__primitives__common.html#gacfc123a6a4ff3b4af4cd27ed66fb8528">DNNL_ARG_DST_LAYER</a>, enc_uni_first_dst_layer_memory}});</div></div><!-- fragment --><p>Encoder : Remaining unidirectional layers </p><div class="fragment"><div class="line">    std::vector&lt;float&gt; user_enc_uni_wei_layer((enc_unidir_n_layers - 1) * 1</div><div class="line">                    * feature_size * lstm_n_gates * feature_size,</div><div class="line">            1.0f);</div><div class="line">    std::vector&lt;float&gt; user_enc_uni_wei_iter((enc_unidir_n_layers - 1) * 1</div><div class="line">                    * feature_size * lstm_n_gates * feature_size,</div><div class="line">            1.0f);</div><div class="line">    std::vector&lt;float&gt; user_enc_uni_bias(</div><div class="line">            (enc_unidir_n_layers - 1) * 1 * lstm_n_gates * feature_size, 1.0f);</div></div><!-- fragment --><p>Encoder : Create unidirection RNN cell </p><div class="fragment"><div class="line">    lstm_forward::desc enc_uni_layer_desc(prop_kind::forward_inference,</div><div class="line">            rnn_direction::unidirectional_left2right,</div><div class="line">            enc_uni_first_dst_layer_md, memory::desc(), memory::desc(),</div><div class="line">            enc_uni_wei_layer_md, enc_uni_wei_iter_md, user_enc_uni_bias_md,</div><div class="line">            enc_dst_layer_md, memory::desc(), memory::desc());</div><div class="line">    <span class="keyword">auto</span> enc_uni_prim_desc = <a class="code" href="structdnnl_1_1lstm__forward_1_1primitive__desc.html">dnnl::lstm_forward::primitive_desc</a>(</div><div class="line">            enc_uni_layer_desc, cpu_engine);</div></div><!-- fragment --><p>Encoder : add the unidirectional rnn primitive with related arguments into encoder_net </p><div class="fragment"><div class="line">    encoder_net.push_back(lstm_forward(enc_uni_prim_desc));</div><div class="line">    encoder_net_args.push_back(</div><div class="line">            {{<a class="code" href="group__dnnl__api__primitives__common.html#gab91ce4d04cf4e98e3a407daa0676764f">DNNL_ARG_SRC_LAYER</a>, enc_uni_first_dst_layer_memory},</div><div class="line">                    {<a class="code" href="group__dnnl__api__primitives__common.html#ga1ac9e1f1327be3902b488b64bae1b4c5">DNNL_ARG_WEIGHTS_LAYER</a>, enc_uni_wei_layer_memory},</div><div class="line">                    {<a class="code" href="group__dnnl__api__primitives__common.html#ga5a9c39486c01ad263e29677a32735af8">DNNL_ARG_WEIGHTS_ITER</a>, enc_uni_wei_iter_memory},</div><div class="line">                    {<a class="code" href="group__dnnl__api__primitives__common.html#gad0cbc09942aba93fbe3c0c2e09166f0d">DNNL_ARG_BIAS</a>, user_enc_uni_bias_memory},</div><div class="line">                    {<a class="code" href="group__dnnl__api__primitives__common.html#gacfc123a6a4ff3b4af4cd27ed66fb8528">DNNL_ARG_DST_LAYER</a>, enc_dst_layer_memory}});</div></div><!-- fragment --><p><b>Decoder with attention mechanism</b></p>
<p>Decoder : declare memory dimensions </p><div class="fragment"><div class="line">    std::vector&lt;float&gt; user_dec_wei_layer(</div><div class="line">            dec_n_layers * 1 * feature_size * lstm_n_gates * feature_size,</div><div class="line">            1.0f);</div><div class="line">    std::vector&lt;float&gt; user_dec_wei_iter(dec_n_layers * 1</div><div class="line">                    * (feature_size + feature_size) * lstm_n_gates</div><div class="line">                    * feature_size,</div><div class="line">            1.0f);</div><div class="line">    std::vector&lt;float&gt; user_dec_bias(</div><div class="line">            dec_n_layers * 1 * lstm_n_gates * feature_size, 1.0f);</div><div class="line">    std::vector&lt;float&gt; user_dec_dst(</div><div class="line">            tgt_seq_length_max * batch * feature_size, 1.0f);</div><div class="line">    std::vector&lt;float&gt; user_weights_attention_src_layer(</div><div class="line">            feature_size * feature_size, 1.0f);</div><div class="line">    std::vector&lt;float&gt; user_weights_annotation(</div><div class="line">            feature_size * feature_size, 1.0f);</div><div class="line">    std::vector&lt;float&gt; user_weights_alignments(feature_size, 1.0f);</div><div class="line"></div><div class="line">    memory::dims user_dec_wei_layer_dims</div><div class="line">            = {dec_n_layers, 1, feature_size, lstm_n_gates, feature_size};</div><div class="line">    memory::dims user_dec_wei_iter_dims = {dec_n_layers, 1,</div><div class="line">            feature_size + feature_size, lstm_n_gates, feature_size};</div><div class="line">    memory::dims user_dec_bias_dims</div><div class="line">            = {dec_n_layers, 1, lstm_n_gates, feature_size};</div><div class="line"></div><div class="line">    memory::dims dec_src_layer_dims = {1, batch, feature_size};</div><div class="line">    memory::dims dec_dst_layer_dims = {1, batch, feature_size};</div><div class="line">    memory::dims dec_dst_iter_c_dims = {dec_n_layers, 1, batch, feature_size};</div></div><!-- fragment --><p>We will use the same memory for dec_src_iter and dec_dst_iter However, dec_src_iter has a context vector but not dec_dst_iter. To resolve this we will create one memory that holds the context vector as well as the both the hidden and cell states. The dst_iter will be a sub-memory of this memory. Note that the cell state will be padded by feature_size values. However, we do not compute or access those. </p><div class="fragment"><div class="line">    memory::dims dec_dst_iter_dims</div><div class="line">            = {dec_n_layers, 1, batch, feature_size + feature_size};</div><div class="line">    memory::dims dec_dst_iter_noctx_dims</div><div class="line">            = {dec_n_layers, 1, batch, feature_size};</div></div><!-- fragment --><p><br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
</p>
<p>Decoder : create memory description </p><div class="fragment"><div class="line">    <span class="keyword">auto</span> user_dec_wei_layer_md = <a class="code" href="structdnnl_1_1memory_1_1desc.html">dnnl::memory::desc</a>({user_dec_wei_layer_dims},</div><div class="line">            <a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dcea512dc597be7ae761876315165dc8bd2e">dnnl::memory::data_type::f32</a>, <a class="code" href="structdnnl_1_1memory.html#a8e71077ed6a5f7fb7b3e6e1a5a2ecf3fa4e62e330c56963f9ead98490cd57ef7b">dnnl::memory::format_tag::ldigo</a>);</div><div class="line">    <span class="keyword">auto</span> user_dec_wei_iter_md = <a class="code" href="structdnnl_1_1memory_1_1desc.html">dnnl::memory::desc</a>({user_dec_wei_iter_dims},</div><div class="line">            <a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dcea512dc597be7ae761876315165dc8bd2e">dnnl::memory::data_type::f32</a>, <a class="code" href="structdnnl_1_1memory.html#a8e71077ed6a5f7fb7b3e6e1a5a2ecf3fa4e62e330c56963f9ead98490cd57ef7b">dnnl::memory::format_tag::ldigo</a>);</div><div class="line">    <span class="keyword">auto</span> user_dec_bias_md = <a class="code" href="structdnnl_1_1memory_1_1desc.html">dnnl::memory::desc</a>({user_dec_bias_dims},</div><div class="line">            <a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dcea512dc597be7ae761876315165dc8bd2e">dnnl::memory::data_type::f32</a>, <a class="code" href="structdnnl_1_1memory.html#a8e71077ed6a5f7fb7b3e6e1a5a2ecf3fab8690cd92ccee6a0ad55faccc0346aab">dnnl::memory::format_tag::ldgo</a>);</div><div class="line">    <span class="keyword">auto</span> dec_dst_layer_md = <a class="code" href="structdnnl_1_1memory_1_1desc.html">dnnl::memory::desc</a>({dec_dst_layer_dims},</div><div class="line">            <a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dcea512dc597be7ae761876315165dc8bd2e">dnnl::memory::data_type::f32</a>, <a class="code" href="structdnnl_1_1memory.html#a8e71077ed6a5f7fb7b3e6e1a5a2ecf3fac775cf954921a129a65eb929476de911">dnnl::memory::format_tag::tnc</a>);</div><div class="line">    <span class="keyword">auto</span> dec_src_layer_md = <a class="code" href="structdnnl_1_1memory_1_1desc.html">dnnl::memory::desc</a>({dec_src_layer_dims},</div><div class="line">            <a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dcea512dc597be7ae761876315165dc8bd2e">dnnl::memory::data_type::f32</a>, <a class="code" href="structdnnl_1_1memory.html#a8e71077ed6a5f7fb7b3e6e1a5a2ecf3fac775cf954921a129a65eb929476de911">dnnl::memory::format_tag::tnc</a>);</div><div class="line">    <span class="keyword">auto</span> dec_dst_iter_md = <a class="code" href="structdnnl_1_1memory_1_1desc.html">dnnl::memory::desc</a>({dec_dst_iter_dims},</div><div class="line">            <a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dcea512dc597be7ae761876315165dc8bd2e">dnnl::memory::data_type::f32</a>, <a class="code" href="structdnnl_1_1memory.html#a8e71077ed6a5f7fb7b3e6e1a5a2ecf3fab49be97ff353a86d84d06d98f846b61d">dnnl::memory::format_tag::ldnc</a>);</div><div class="line">    <span class="keyword">auto</span> dec_dst_iter_c_md = <a class="code" href="structdnnl_1_1memory_1_1desc.html">dnnl::memory::desc</a>({dec_dst_iter_c_dims},</div><div class="line">            <a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dcea512dc597be7ae761876315165dc8bd2e">dnnl::memory::data_type::f32</a>, <a class="code" href="structdnnl_1_1memory.html#a8e71077ed6a5f7fb7b3e6e1a5a2ecf3fab49be97ff353a86d84d06d98f846b61d">dnnl::memory::format_tag::ldnc</a>);</div></div><!-- fragment --><p>Decoder : Create memory </p><div class="fragment"><div class="line">    <span class="keyword">auto</span> user_dec_wei_layer_memory = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(</div><div class="line">            user_dec_wei_layer_md, cpu_engine, user_dec_wei_layer.data());</div><div class="line">    <span class="keyword">auto</span> user_dec_wei_iter_memory = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(</div><div class="line">            user_dec_wei_iter_md, cpu_engine, user_dec_wei_iter.data());</div><div class="line">    <span class="keyword">auto</span> user_dec_bias_memory</div><div class="line">            = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(user_dec_bias_md, cpu_engine, user_dec_bias.data());</div><div class="line">    <span class="keyword">auto</span> user_dec_dst_layer_memory</div><div class="line">            = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(dec_dst_layer_md, cpu_engine, user_dec_dst.data());</div><div class="line">    <span class="keyword">auto</span> dec_src_layer_memory = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(dec_src_layer_md, cpu_engine);</div><div class="line">    <span class="keyword">auto</span> dec_dst_iter_c_memory = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(dec_dst_iter_c_md, cpu_engine);</div></div><!-- fragment --><p>Decoder : As mentioned above, we create a view without context out of the memory with context. </p><div class="fragment"><div class="line">    <span class="keyword">auto</span> dec_dst_iter_memory = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(dec_dst_iter_md, cpu_engine);</div><div class="line">    <span class="keyword">auto</span> dec_dst_iter_noctx_md = dec_dst_iter_md.<a class="code" href="structdnnl_1_1memory_1_1desc.html#a3573d45ed89399339ad2af05b8097a3a">submemory_desc</a>(</div><div class="line">            dec_dst_iter_noctx_dims, {0, 0, 0, 0, 0});</div></div><!-- fragment --><p>Decoder : Create RNN decoder cell </p><div class="fragment"><div class="line">    lstm_forward::desc dec_ctx_desc(prop_kind::forward_inference,</div><div class="line">            rnn_direction::unidirectional_left2right, dec_src_layer_md,</div><div class="line">            dec_dst_iter_md, dec_dst_iter_c_md, dec_wei_layer_md,</div><div class="line">            dec_wei_iter_md, user_dec_bias_md, dec_dst_layer_md,</div><div class="line">            dec_dst_iter_noctx_md, dec_dst_iter_c_md);</div><div class="line">    <span class="keyword">auto</span> dec_ctx_prim_desc</div><div class="line">            = <a class="code" href="structdnnl_1_1lstm__forward_1_1primitive__desc.html">dnnl::lstm_forward::primitive_desc</a>(dec_ctx_desc, cpu_engine);</div></div><!-- fragment --><p>Decoder : reorder weight memory </p><div class="fragment"><div class="line">    <span class="keyword">auto</span> dec_wei_layer_memory</div><div class="line">            = memory(dec_ctx_prim_desc.weights_layer_desc(), cpu_engine);</div><div class="line">    <span class="keyword">auto</span> dec_wei_layer_reorder_pd = reorder::primitive_desc(</div><div class="line">            user_dec_wei_layer_memory, dec_wei_layer_memory);</div><div class="line">    reorder(dec_wei_layer_reorder_pd)</div><div class="line">            .execute(s, user_dec_wei_layer_memory, dec_wei_layer_memory);</div><div class="line"></div><div class="line">    <span class="keyword">auto</span> dec_wei_iter_memory</div><div class="line">            = memory(dec_ctx_prim_desc.weights_iter_desc(), cpu_engine);</div><div class="line">    <span class="keyword">auto</span> dec_wei_iter_reorder_pd = reorder::primitive_desc(</div><div class="line">            user_dec_wei_iter_memory, dec_wei_iter_memory);</div><div class="line">    reorder(dec_wei_iter_reorder_pd)</div><div class="line">            .execute(s, user_dec_wei_iter_memory, dec_wei_iter_memory);</div></div><!-- fragment --><p>Decoder : add the rnn primitive with related arguments into decoder_net </p><div class="fragment"><div class="line">    <span class="comment">// TODO: add a reorder when they will be available</span></div><div class="line">    decoder_net.push_back(lstm_forward(dec_ctx_prim_desc));</div><div class="line">    decoder_net_args.push_back({{<a class="code" href="group__dnnl__api__primitives__common.html#gab91ce4d04cf4e98e3a407daa0676764f">DNNL_ARG_SRC_LAYER</a>, dec_src_layer_memory},</div><div class="line">            {<a class="code" href="group__dnnl__api__primitives__common.html#gaf35f4f604284f1b00bb35bffd0f7a143">DNNL_ARG_SRC_ITER</a>, dec_dst_iter_memory},</div><div class="line">            {<a class="code" href="group__dnnl__api__primitives__common.html#ga8ef6969516e717208a33766542410410">DNNL_ARG_SRC_ITER_C</a>, dec_dst_iter_c_memory},</div><div class="line">            {<a class="code" href="group__dnnl__api__primitives__common.html#ga1ac9e1f1327be3902b488b64bae1b4c5">DNNL_ARG_WEIGHTS_LAYER</a>, dec_wei_layer_memory},</div><div class="line">            {<a class="code" href="group__dnnl__api__primitives__common.html#ga5a9c39486c01ad263e29677a32735af8">DNNL_ARG_WEIGHTS_ITER</a>, dec_wei_iter_memory},</div><div class="line">            {<a class="code" href="group__dnnl__api__primitives__common.html#gad0cbc09942aba93fbe3c0c2e09166f0d">DNNL_ARG_BIAS</a>, user_dec_bias_memory},</div><div class="line">            {<a class="code" href="group__dnnl__api__primitives__common.html#gacfc123a6a4ff3b4af4cd27ed66fb8528">DNNL_ARG_DST_LAYER</a>, user_dec_dst_layer_memory},</div><div class="line">            {<a class="code" href="group__dnnl__api__primitives__common.html#ga13b91cbd3f531d9c90227895a275d5a6">DNNL_ARG_DST_ITER</a>, dec_dst_iter_memory},</div><div class="line">            {<a class="code" href="group__dnnl__api__primitives__common.html#ga8b77d8716fc0ab9923d6cb409dbdf900">DNNL_ARG_DST_ITER_C</a>, dec_dst_iter_c_memory}});</div></div><!-- fragment --><p><b>Execution</b></p>
<p>run encoder (1 stream) </p><div class="fragment"><div class="line">        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> p = 0; p &lt; encoder_net.size(); ++p)</div><div class="line">            encoder_net.at(p).execute(s, encoder_net_args.at(p));</div></div><!-- fragment --><p>we compute the weighted annotations once before the decoder </p><div class="fragment"><div class="line">        compute_weighted_annotations(weighted_annotations.data(),</div><div class="line">                src_seq_length_max, batch, feature_size,</div><div class="line">                user_weights_annotation.data(),</div><div class="line">                (<span class="keywordtype">float</span> *)enc_dst_layer_memory.get_data_handle());</div></div><!-- fragment --><p>We initialize src_layer to the embedding of the end of sequence character, which are assumed to be 0 here </p><div class="fragment"><div class="line">        memset(dec_src_layer_memory.<a class="code" href="structdnnl_1_1memory.html#a8968c24c4a95255f68ab2a483769343d">get_data_handle</a>(), 0,</div><div class="line">                dec_src_layer_memory.<a class="code" href="structdnnl_1_1memory.html#ad8a1ad28ed7acf9c34c69e4b882c6e92">get_desc</a>().<a class="code" href="structdnnl_1_1memory_1_1desc.html#ac20108bc192912382aa4a95ae27df804">get_size</a>());</div></div><!-- fragment --><p>From now on, src points to the output of the last iteration</p>
<p>Compute attention context vector into the first layer src_iter </p><div class="fragment"><div class="line">            compute_attention(src_att_iter_handle, src_seq_length_max, batch,</div><div class="line">                    feature_size, user_weights_attention_src_layer.data(),</div><div class="line">                    src_att_layer_handle,</div><div class="line">                    (<span class="keywordtype">float</span> *)enc_bidir_dst_layer_memory.get_data_handle(),</div><div class="line">                    weighted_annotations.data(),</div><div class="line">                    user_weights_alignments.data());</div></div><!-- fragment --><p>copy the context vectors to all layers of src_iter </p><div class="fragment"><div class="line">            copy_context(</div><div class="line">                    src_att_iter_handle, dec_n_layers, batch, feature_size);</div></div><!-- fragment --><p>run the decoder iteration </p><div class="fragment"><div class="line">            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> p = 0; p &lt; decoder_net.size(); ++p)</div><div class="line">                decoder_net.at(p).execute(s, decoder_net_args.at(p));</div></div><!-- fragment --><p>Move the handle on the src/dst layer to the next iteration </p><div class="fragment"><div class="line">            <span class="keyword">auto</span> dst_layer_handle</div><div class="line">                    = (<span class="keywordtype">float</span> *)user_dec_dst_layer_memory.<a class="code" href="structdnnl_1_1memory.html#a8968c24c4a95255f68ab2a483769343d">get_data_handle</a>();</div><div class="line">            dec_src_layer_memory.<a class="code" href="structdnnl_1_1memory.html#a9dd1676860851db76fcabbc437ab375f">set_data_handle</a>(dst_layer_handle);</div><div class="line">            user_dec_dst_layer_memory.<a class="code" href="structdnnl_1_1memory.html#a9dd1676860851db76fcabbc437ab375f">set_data_handle</a>(</div><div class="line">                    dst_layer_handle + batch * feature_size);</div></div><!-- fragment --></div></div><!-- contents -->
<div class="footer">
    <div class="footer-wrapper">
        <ul id="footer-links">
            <li><a href="legal_information.html">Legal information</a></li>
        </ul>
    </div>
</div>