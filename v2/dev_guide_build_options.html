<!-- HTML header for doxygen 1.8.5-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width,initial-scale=1.0">
<title>oneDNN: Build Options</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(initResizable);
/* @license-end */</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<script src="assets/mathjax/MathJax.js?config=TeX-AMS_CHTML,dnnl"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="assets/customdoxygen.css" rel="stylesheet" type="text/css" />
<script type="text/javascript" src="assets/dnn.js"></script>
</head>
<body>
<div class="mobile-nav"><i id="nav-btn"></i><a href="index.html">oneAPI Deep Neural Network Library (oneDNN)</a></div>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
   <div id="projectname">
     <a href="index.html">
      <div id="full-name">oneAPI Deep Neural Network Library (oneDNN)</div>
    </a>
   </div>
   <div id="projectbrief">Performance library for Deep Learning</div>
   <div id="projectnumber">1.96.0</div>
  <div>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
</div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('dev_guide_build_options.html','');});
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Build Options </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>oneDNN supports the following build-time options.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadLeft">CMake Option  </th><th class="markdownTableHeadLeft">Supported values (defaults in bold)  </th><th class="markdownTableHeadLeft">Desc   </th></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">DNNL_LIBRARY_TYPE  </td><td class="markdownTableBodyLeft"><b>SHARED</b>, STATIC  </td><td class="markdownTableBodyLeft">Defines the resulting library type   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyLeft">DNNL_CPU_RUNTIME  </td><td class="markdownTableBodyLeft"><b>OMP</b>, TBB, SEQ, THREADPOOL, DPCPP  </td><td class="markdownTableBodyLeft">Defines the threading runtime for CPU engines   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">DNNL_GPU_RUNTIME  </td><td class="markdownTableBodyLeft"><b>NONE</b>, OCL, DPCPP  </td><td class="markdownTableBodyLeft">Defines the offload runtime for GPU engines   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyLeft">DNNL_BUILD_EXAMPLES  </td><td class="markdownTableBodyLeft"><b>ON</b>, OFF  </td><td class="markdownTableBodyLeft">Controls building the examples   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">DNNL_BUILD_TESTS  </td><td class="markdownTableBodyLeft"><b>ON</b>, OFF  </td><td class="markdownTableBodyLeft">Controls building the tests   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyLeft">DNNL_ARCH_OPT_FLAGS  </td><td class="markdownTableBodyLeft"><em>compiler flags</em>  </td><td class="markdownTableBodyLeft">Specifies compiler optimization flags (see warning note below)   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">DNNL_ENABLE_CONCURRENT_EXEC  </td><td class="markdownTableBodyLeft">ON, <b>OFF</b>  </td><td class="markdownTableBodyLeft">Disables sharing a common scratchpad between primitives in <a class="el" href="group__dnnl__api__attributes.html#ggac24d40ceea0256c7d6cc3a383a0fa07fad521f765a49c72507257a2620612ee96" title="The library manages the scratchpad allocation according to the policy specified by the DNNL_ENABLE_CO...">dnnl::scratchpad_mode::library</a> mode   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyLeft">DNNL_ENABLE_JIT_PROFILING  </td><td class="markdownTableBodyLeft"><b>ON</b>, OFF  </td><td class="markdownTableBodyLeft">Enables <a class="el" href="dev_guide_profilers.html">integration with performance profilers</a>   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">DNNL_ENABLE_PRIMITIVE_CACHE  </td><td class="markdownTableBodyLeft"><b>ON</b>, OFF  </td><td class="markdownTableBodyLeft">Enables <a class="el" href="dev_guide_primitive_cache.html">primitive cache</a>   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyLeft">DNNL_ENABLE_MAX_CPU_ISA  </td><td class="markdownTableBodyLeft"><b>ON</b>, OFF  </td><td class="markdownTableBodyLeft">Enables <a class="el" href="dev_guide_cpu_dispatcher_control.html">CPU dispatcher controls</a>   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">DNNL_VERBOSE  </td><td class="markdownTableBodyLeft"><b>ON</b>, OFF  </td><td class="markdownTableBodyLeft">Enables <a class="el" href="dev_guide_verbose.html">verbose mode</a>   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyLeft">DNNL_AARCH64_USE_ACL  </td><td class="markdownTableBodyLeft">ON, <b>OFF</b>  </td><td class="markdownTableBodyLeft">Enables integration with Arm Compute Library for AArch64 builds   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">DNNL_BLAS_VENDOR  </td><td class="markdownTableBodyLeft"><b>NONE</b>, ARMPL  </td><td class="markdownTableBodyLeft">Defines an external BLAS library to link to for GEMM-like operations   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyLeft">DNNL_GPU_VENDOR  </td><td class="markdownTableBodyLeft"><b>INTEL</b>, NVIDIA  </td><td class="markdownTableBodyLeft">Defines GPU vendor for GPU engines   </td></tr>
</table>
<p>All other building options or values that can be found in CMake files are intended for development/debug purposes and are subject to change without notice. Please avoid using them.</p>
<h2>Common options</h2>
<h2>CPU Options</h2>
<p>Intel Architecture Processors and compatible devices are supported by oneDNN CPU engine. The CPU engine is built by default and cannot be disabled at build time.</p>
<h3>Targeting Specific Architecture</h3>
<p>oneDNN uses JIT code generation to implement most of its functionality and will choose the best code based on detected processor features. However, some oneDNN functionality will still benefit from targeting a specific processor architecture at build time. You can use <code>DNNL_ARCH_OPT_FLAGS</code> CMake option for this.</p>
<p>For Intel(R) C++ Compilers, the default option is <code>-xSSE4.1</code>, which instructs the compiler to generate the code for the processors that support SSE4.1 instructions. This option would not allow you to run the library on older processor architectures.</p>
<p>For GNU* Compilers and Clang, the default option is <code>-msse4.1</code>.</p>
<dl class="section warning"><dt>Warning</dt><dd>While use of <code>DNNL_ARCH_OPT_FLAGS</code> option gives better performance, the resulting library can be run only on systems that have instruction set compatible with the target instruction set. Therefore, <code>ARCH_OPT_FLAGS</code> should be set to an empty string (<code>""</code>) if the resulting library needs to be portable.</dd></dl>
<h3>Runtime CPU dispatcher control</h3>
<p>oneDNN JIT relies on ISA features obtained from the processor it is being run on. There are situations when it is necessary to control this behavior at run-time to, for example, test SSE4.1 code on an AVX2-capable processor. The <code>DNNL_ENABLE_MAX_CPU_ISA</code> build option controls the availability of this feature. See <a class="el" href="dev_guide_cpu_dispatcher_control.html">CPU Dispatcher Control</a> for more information.</p>
<h3>Runtimes</h3>
<p>CPU engine can use OpenMP, Threading Building Blocks (TBB) or sequential threading runtimes. OpenMP threading is the default build mode. This behavior is controlled by the <code>DNNL_CPU_RUNTIME</code> CMake option.</p>
<h4>OpenMP</h4>
<p>oneDNN uses OpenMP runtime library provided by the compiler.</p>
<dl class="section warning"><dt>Warning</dt><dd>Because different OpenMP runtimes may not be binary-compatible, it's important to ensure that only one OpenMP runtime is used throughout the application. Having more than one OpenMP runtime linked to an executable may lead to undefined behavior including incorrect results or crashes. However as long as both the library and the application use the same or compatible compilers there would be no conflicts.</dd></dl>
<h4>Threading Building Blocks (TBB)</h4>
<p>To build oneDNN with TBB support, set <code>DNNL_CPU_RUNTIME</code> to <code>TBB</code>:</p>
<div class="fragment"><div class="line">$ cmake -DDNNL_CPU_RUNTIME=TBB ..</div></div><!-- fragment --><p>Optionally, set the <code>TBBROOT</code> environmental variable to point to the TBB installation path or pass the path directly to CMake:</p>
<div class="fragment"><div class="line">$ cmake -DDNNL_CPU_RUNTIME=TBB -DTBBROOT=/opt/intel/path/tbb ..</div></div><!-- fragment --><p>oneDNN has functional limitations if built with TBB:</p><ul>
<li>Winograd convolution algorithm is not supported for fp32 backward by data and backward by weights propagation.</li>
</ul>
<h4>Threadpool</h4>
<p>To build oneDNN with support for threadpool threading, set <code>DNNL_CPU_RUNTIME</code> to <code>THREADPOOL</code></p>
<div class="fragment"><div class="line">$ cmake -DDNNL_CPU_RUNTIME=THREADPOOL ..</div></div><!-- fragment --><p>The <code>_DNNL_TEST_THREADPOOL_IMPL</code> CMake variable controls which of the three threadpool implementations would be used for testing: <code>STANDALONE</code>, <code>TBB</code>, or <code>EIGEN</code>. The latter two require also passing <code>TBBROOT</code> or <code>Eigen3_DIR</code> paths to CMake. For example:</p>
<div class="fragment"><div class="line">$ cmake -DDNNL_CPU_RUNTIME=THREADPOOL -D_DNNL_TEST_THREADPOOL_IMPL=EIGEN -DEigen3_DIR=/path/to/eigen/share/eigen3/cmake ..</div></div><!-- fragment --><p>Threadpool threading support is experimental and has the same limitations as TBB plus more:</p><ul>
<li>As threadpools are attached to streams which are only passed during primitive execution, work decomposition is performed statically at the primitive creation time. At the primitive execution time, the threadpool is responsible for balancing the static decomposition from the previous item across available worker threads.</li>
</ul>
<h3>AArch64 Options</h3>
<p>oneDNN includes experimental support for Arm 64-bit Architecture (AArch64). By default, AArch64 builds will use the reference implementations throughout. The following options enable the use of AArch64 optimised implementations for a limited number of operations, provided by AArch64 libraries.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadLeft">AArch64 build configuration  </th><th class="markdownTableHeadLeft">CMake Option  </th><th class="markdownTableHeadLeft">Environment variables  </th><th class="markdownTableHeadLeft">Depe   </th></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">Arm Compute Library based primitives  </td><td class="markdownTableBodyLeft">DNNL_AARCH64_USE_ACL=ON  </td><td class="markdownTableBodyLeft">ACL_ROOT_DIR=*Arm Compute Library location*  </td><td class="markdownTableBodyLeft"><a href="https://github.com/ARM-software/ComputeLibrary">Arm Compute Library</a>   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyLeft">Vendor BLAS library support  </td><td class="markdownTableBodyLeft">DNNL_BLAS_VENDOR=ARMPL  </td><td class="markdownTableBodyLeft">None  </td><td class="markdownTableBodyLeft"><a href="https://developer.arm.com/tools-and-software/server-and-hpc/downloads/arm-performance-libraries">Arm Performance Libraries</a>   </td></tr>
</table>
<h4>Arm Compute Library</h4>
<p>Arm Compute Library is an open-source library for computer vision and machine learning applications. The development repository is available from <a href="https://review.mlplatform.org/#/admin/projects/ml/ComputeLibrary">mlplatform.org</a>, and releases are also available on <a href="https://github.com/ARM-software/ComputeLibrary">GitHub</a>. The <code>DNNL_AARCH64_USE_ACL</code> CMake option is used to enable Compute Library integration:</p>
<div class="fragment"><div class="line">$ cmake -DDNNL_AARCH64_USE_ACL=ON ..</div></div><!-- fragment --><p>This assumes that the environment variable <code>ACL_ROOT_DIR</code> is set to the location of Arm Compute Library, which must be downloaded and built independently of oneDNN.</p>
<dl class="section warning"><dt>Warning</dt><dd>For a debug build of oneDNN it is advisable to specify a Compute Library build which has also been built with debug enabled.</dd></dl>
<h4>Vendor BLAS libraries</h4>
<p>oneDNN can use a standard BLAS library for GEMM operations. The <code>DNNL_BLAS_VENDOR</code> build option controls BLAS library selection, and defaults to <code>NONE</code>. For AArch64 builds with GCC, use the <a href="https://developer.arm.com/tools-and-software/server-and-hpc/downloads/arm-performance-libraries">Arm Performance Libraries</a>:</p>
<div class="fragment"><div class="line">$ cmake -DDNNL_BLAS_VENDOR=ARMPL ..</div></div><!-- fragment --><p>Additional options available for development/debug purposes. These options are subject to change without notice, see <a href="https://github.com/oneapi-src/oneDNN/blob/master/cmake/options.cmake"><code>cmake/options.cmake</code></a> for details.</p>
<h2>GPU Options</h2>
<p>Intel Processor Graphics is supported by oneDNN GPU engine. GPU engine is disabled in the default build configuration.</p>
<h3>Runtimes</h3>
<p>To enable GPU support you need to specify the GPU runtime by setting <code>DNNL_GPU_RUNTIME</code> CMake option. The default value is <code>"NONE"</code> which corresponds to no GPU support in the library.</p>
<h4>OpenCL*</h4>
<p>OpenCL runtime requires Intel(R) SDK for OpenCL* applications. You can explicitly specify the path to the SDK using <code>-DOPENCLROOT</code> CMake option.</p>
<div class="fragment"><div class="line">$ cmake -DDNNL_GPU_RUNTIME=OCL -DOPENCLROOT=/path/to/opencl/sdk ..</div></div><!-- fragment --> </div></div><!-- contents -->
</div><!-- doc-content -->
<div class="footer">
    <script>
        $('#top').prependTo($('#side-nav'));
    </script>
    <div class="footer-wrapper">
        <hr>
        <ul class="footer-links">
            <li><a href="legal_information.html">Legal information</a></li>
        </ul>
    </div>
</div>